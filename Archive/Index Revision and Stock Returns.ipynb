{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b543aa1c",
   "metadata": {},
   "source": [
    "# Guided Studies into Financial Management\n",
    "## Index Revisions and Stock Returns\n",
    "\n",
    "### Colaborators\n",
    "Dennis Blaufuss,\n",
    "Lars Wrede,\n",
    "Nicolas Kepper,\n",
    "Sophie Merl,\n",
    "Philipp Voit\n",
    "\n",
    "### Instructor\n",
    "Dr. Stefan Scharnoski\n",
    "\n",
    "### Summary \n",
    "HIER MÜSSEN WIR NOCH EINE ZUSAMMENFASSUNG DER ERGEBNISSE SCHREIBEN - WIE ABSTRACT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc04ce",
   "metadata": {},
   "source": [
    "## Table of Content:\n",
    "1. [Data Proprocessing](#0-bullet)\n",
    "* [Import Data](#first-bullet)\n",
    "* [Calculate Daily Returns](#2-bullet)\n",
    "* [Data Quality Checks](#3-bullet)\n",
    "* [Descriptive Statistics](#4-bullet)\n",
    "2. [Price Pressure](#5-bullet)\n",
    "3. [Investor Attention](#6-bullet)\n",
    "4. [Systematic Risk and Liquidity](#7-bullet)\n",
    "* [Systematic Risk - Included Stocks](#8-bullet)\n",
    "* [Systematic Risk - Excluded Stocks](#9-bullet)\n",
    "* [Systematic Risk - DAX 30 to DAX 40](#10-bullet)\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ae388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import performanceanalytics.table.table as pat\n",
    "from performanceanalytics.charts import performance_summary\n",
    "import statistics\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c20c3",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing <a class=\"anchor\" id=\"0-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164152d1",
   "metadata": {},
   "source": [
    "## Import Data <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbe7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import all relevant data.\n",
    "Parameters\n",
    "----------\n",
    ":DAX_aufgenommen: df\n",
    "    All stocks included in the DAX from 2010 until 2021.\n",
    ":DAX_ausgeschieden: df\n",
    "    All stocks excluded from the DAX from 2010 until 2021.\n",
    ":stock_data: df\n",
    "    Contains stock ticker as well as names of the stocks of all DAX stock from 22-03-01.\n",
    ":benchmark:  df\n",
    "    The MSCI Germany Index was used as a proxy for the market portfolio. \n",
    "    This index contains a large number of M-DAX and DAX stocks and is therefore more \n",
    "    broadly structured than the DAX. However, the high weight of the DAX shares in the index is problematic, \n",
    "    so that it is to be expected that the actual influence is underestimated.\n",
    ":index_compositions: df\n",
    "    Contains the deletions/ additions as well as date of change/ announcements & Merger/Spin-Off Information.\n",
    "-------\n",
    "'''\n",
    "DAX_included = pd.read_csv('DAX_included_2010-2021.csv', sep = ';')\n",
    "DAX_excluded = pd.read_csv('DAX_excluded_2010-2021.csv', sep = ';')\n",
    "stock_data = pd.read_csv('Companies_Ticker.csv', sep = ';')\n",
    "benchmark = pd.read_csv('DAX_Kurs.csv', sep = ';')\n",
    "announcements = pd.read_csv('Historical_Index_Compositions.csv', sep = ';')\n",
    "stockdata = pd.read_csv('stocks-historical-data.csv', sep = ';')\n",
    "#index_compositions = pd.read_csv('Historical_Index_Compositions.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619fda1",
   "metadata": {},
   "source": [
    "## Creating Info DataFrame <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84f0bb",
   "metadata": {},
   "source": [
    "* Joining all Stocks that where at some point in time after 2010 in the DAX.\n",
    "* Stocks that were in the Dax the whole time have will have all movement related columns set to N/A.\n",
    "* Both dates are formatted in pandas datetime format.\n",
    "* Symbol stands for the Yahoo Finance Ticker while Ticker is the Reuters one. This is due to the fact, that we first worked with yf but then switched to Reuters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50467f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Firmenname</th>\n",
       "      <th>Type</th>\n",
       "      <th>Announcement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-21</td>\n",
       "      <td>SZG.DE</td>\n",
       "      <td>Salzgitter AG</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2010-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>LXS.DE</td>\n",
       "      <td>LANXESS Aktiengesellschaft</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2015-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>SDF.DE</td>\n",
       "      <td>K+S Aktiengesellschaft</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2016-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>PSM.DE</td>\n",
       "      <td>ProSiebenSat.1 Media SE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2018-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>CBK.DE</td>\n",
       "      <td>Commerzbank AG</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2018-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>TKA.DE</td>\n",
       "      <td>thyssenkrupp AG</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2019-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>LHA.DE</td>\n",
       "      <td>Deutsche Lufthansa AG</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2020-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>WDI.HM</td>\n",
       "      <td>Wirecard AG</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2020-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>BEI.DE</td>\n",
       "      <td>Beiersdorf Aktiengesellschaft</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2021-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>DWNI.DE</td>\n",
       "      <td>Deutsche Wohnen SE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>2021-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2010-06-21</td>\n",
       "      <td>HEI.DE</td>\n",
       "      <td>HeidelbergCement AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2010-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-09-24</td>\n",
       "      <td>CON.DE</td>\n",
       "      <td>Continental Aktiengesellschaft</td>\n",
       "      <td>Included</td>\n",
       "      <td>2012-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-09-24</td>\n",
       "      <td>LXS.DE</td>\n",
       "      <td>LANXESS Aktiengesellschaft</td>\n",
       "      <td>Included</td>\n",
       "      <td>2012-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>VNA.DE</td>\n",
       "      <td>Vonovia SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2015-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016-03-21</td>\n",
       "      <td>PSM.DE</td>\n",
       "      <td>ProSiebenSat.1 Media SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2016-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-03-19</td>\n",
       "      <td>1COV.DE</td>\n",
       "      <td>Covestro AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2018-05-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-09-24</td>\n",
       "      <td>WDI.HM</td>\n",
       "      <td>Wirecard AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2018-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-09-23</td>\n",
       "      <td>MTX.DE</td>\n",
       "      <td>MTU Aero Engines AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2019-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-06-22</td>\n",
       "      <td>DWNI.DE</td>\n",
       "      <td>Deutsche Wohnen SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2020-04-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>DHER.DE</td>\n",
       "      <td>Delivery Hero SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2020-08-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>ENR.DE</td>\n",
       "      <td>Siemens Energy AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>BEI.DE</td>\n",
       "      <td>Beiersdorf Aktiengesellschaft</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-10-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>AIR.DE</td>\n",
       "      <td>Airbus SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>BNR.DE</td>\n",
       "      <td>Brenntag SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>HFG.DE</td>\n",
       "      <td>HelloFresh SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>POAHY</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>PUM.DE</td>\n",
       "      <td>PUMA SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>QIA.DE</td>\n",
       "      <td>Qiagen</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>SRT3.DE</td>\n",
       "      <td>Sartorius AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>SHL.DE</td>\n",
       "      <td>Siemens Healthineers AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>SY1.DE</td>\n",
       "      <td>Symrise AG</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2021-09-20</td>\n",
       "      <td>ZAL.DE</td>\n",
       "      <td>Zalando SE</td>\n",
       "      <td>Included</td>\n",
       "      <td>2021-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaT</td>\n",
       "      <td>^GDAXI</td>\n",
       "      <td>DAX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaT</td>\n",
       "      <td>ADS.DE</td>\n",
       "      <td>adidas AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaT</td>\n",
       "      <td>ALV.DE</td>\n",
       "      <td>Allianz SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaT</td>\n",
       "      <td>BAS.DE</td>\n",
       "      <td>BASF SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaT</td>\n",
       "      <td>BAYN.DE</td>\n",
       "      <td>Bayer Aktiengesellschaft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaT</td>\n",
       "      <td>BMW.DE</td>\n",
       "      <td>Bayerische Motoren Werke Aktiengesellschaft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaT</td>\n",
       "      <td>DBK.DE</td>\n",
       "      <td>Deutsche Bank AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaT</td>\n",
       "      <td>DB1.DE</td>\n",
       "      <td>Deutsche Boerse AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaT</td>\n",
       "      <td>DPW.DE</td>\n",
       "      <td>Deutsche Post AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaT</td>\n",
       "      <td>DTE.DE</td>\n",
       "      <td>Deutsche Telekom AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaT</td>\n",
       "      <td>EON.BR</td>\n",
       "      <td>E.ON SE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaT</td>\n",
       "      <td>FME.DE</td>\n",
       "      <td>Fresenius Medical Care AG &amp; Co. KGaA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaT</td>\n",
       "      <td>FRE.DE</td>\n",
       "      <td>Fresenius SE &amp; Co. KGaA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaT</td>\n",
       "      <td>HEN3.DE</td>\n",
       "      <td>Henkel AG &amp; Co. KGaA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaT</td>\n",
       "      <td>IFX.DE</td>\n",
       "      <td>Infineon Technologies AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaT</td>\n",
       "      <td>LIN.DE</td>\n",
       "      <td>Linde plc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaT</td>\n",
       "      <td>MBG.DE</td>\n",
       "      <td>Mercedes-Benz Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaT</td>\n",
       "      <td>MRK.DE</td>\n",
       "      <td>MERCK Kommanditgesellschaft auf Aktien</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaT</td>\n",
       "      <td>MUV2.DE</td>\n",
       "      <td>Münchner Rückversicherungs-Gesellschaft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaT</td>\n",
       "      <td>RWE.DE</td>\n",
       "      <td>RWE AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaT</td>\n",
       "      <td>SAP.DE</td>\n",
       "      <td>SAP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaT</td>\n",
       "      <td>SIE.DE</td>\n",
       "      <td>Siemens Aktiengesellschaft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NaT</td>\n",
       "      <td>VOW3.DE</td>\n",
       "      <td>Volkswagen AG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Symbol                                   Firmenname      Type  \\\n",
       "0  2010-06-21   SZG.DE                                Salzgitter AG  Excluded   \n",
       "1  2015-09-21   LXS.DE                   LANXESS Aktiengesellschaft  Excluded   \n",
       "2  2016-03-21   SDF.DE                       K+S Aktiengesellschaft  Excluded   \n",
       "3  2018-03-19   PSM.DE                      ProSiebenSat.1 Media SE  Excluded   \n",
       "4  2018-09-24   CBK.DE                               Commerzbank AG  Excluded   \n",
       "5  2019-09-23   TKA.DE                              thyssenkrupp AG  Excluded   \n",
       "6  2020-06-22   LHA.DE                        Deutsche Lufthansa AG  Excluded   \n",
       "7  2020-08-24   WDI.HM                                  Wirecard AG  Excluded   \n",
       "8  2021-03-22   BEI.DE                Beiersdorf Aktiengesellschaft  Excluded   \n",
       "9  2021-10-29  DWNI.DE                           Deutsche Wohnen SE  Excluded   \n",
       "10 2010-06-21   HEI.DE                          HeidelbergCement AG  Included   \n",
       "11 2012-09-24   CON.DE               Continental Aktiengesellschaft  Included   \n",
       "12 2012-09-24   LXS.DE                   LANXESS Aktiengesellschaft  Included   \n",
       "13 2015-09-21   VNA.DE                                   Vonovia SE  Included   \n",
       "14 2016-03-21   PSM.DE                      ProSiebenSat.1 Media SE  Included   \n",
       "15 2018-03-19  1COV.DE                                  Covestro AG  Included   \n",
       "16 2018-09-24   WDI.HM                                  Wirecard AG  Included   \n",
       "17 2019-09-23   MTX.DE                          MTU Aero Engines AG  Included   \n",
       "18 2020-06-22  DWNI.DE                           Deutsche Wohnen SE  Included   \n",
       "19 2020-08-24  DHER.DE                             Delivery Hero SE  Included   \n",
       "20 2021-03-22   ENR.DE                            Siemens Energy AG  Included   \n",
       "21 2021-10-29   BEI.DE                Beiersdorf Aktiengesellschaft  Included   \n",
       "22 2021-09-20   AIR.DE                                    Airbus SE  Included   \n",
       "23 2021-09-20   BNR.DE                                  Brenntag SE  Included   \n",
       "24 2021-09-20   HFG.DE                                HelloFresh SE  Included   \n",
       "25 2021-09-20    POAHY                                      Porsche  Included   \n",
       "26 2021-09-20   PUM.DE                                      PUMA SE  Included   \n",
       "27 2021-09-20   QIA.DE                                       Qiagen  Included   \n",
       "28 2021-09-20  SRT3.DE                                 Sartorius AG  Included   \n",
       "29 2021-09-20   SHL.DE                      Siemens Healthineers AG  Included   \n",
       "30 2021-09-20   SY1.DE                                   Symrise AG  Included   \n",
       "31 2021-09-20   ZAL.DE                                   Zalando SE  Included   \n",
       "32        NaT   ^GDAXI                                          DAX       NaN   \n",
       "33        NaT   ADS.DE                                    adidas AG       NaN   \n",
       "34        NaT   ALV.DE                                   Allianz SE       NaN   \n",
       "35        NaT   BAS.DE                                      BASF SE       NaN   \n",
       "36        NaT  BAYN.DE                     Bayer Aktiengesellschaft       NaN   \n",
       "37        NaT   BMW.DE  Bayerische Motoren Werke Aktiengesellschaft       NaN   \n",
       "38        NaT   DBK.DE                             Deutsche Bank AG       NaN   \n",
       "39        NaT   DB1.DE                           Deutsche Boerse AG       NaN   \n",
       "40        NaT   DPW.DE                             Deutsche Post AG       NaN   \n",
       "41        NaT   DTE.DE                          Deutsche Telekom AG       NaN   \n",
       "42        NaT   EON.BR                                      E.ON SE       NaN   \n",
       "43        NaT   FME.DE         Fresenius Medical Care AG & Co. KGaA       NaN   \n",
       "44        NaT   FRE.DE                      Fresenius SE & Co. KGaA       NaN   \n",
       "45        NaT  HEN3.DE                        Henkel AG & Co. KGaA        NaN   \n",
       "46        NaT   IFX.DE                     Infineon Technologies AG       NaN   \n",
       "47        NaT   LIN.DE                                    Linde plc       NaN   \n",
       "48        NaT   MBG.DE                         Mercedes-Benz Group        NaN   \n",
       "49        NaT   MRK.DE       MERCK Kommanditgesellschaft auf Aktien       NaN   \n",
       "50        NaT  MUV2.DE      Münchner Rückversicherungs-Gesellschaft       NaN   \n",
       "51        NaT   RWE.DE                                       RWE AG       NaN   \n",
       "52        NaT   SAP.DE                                          SAP       NaN   \n",
       "53        NaT   SIE.DE                   Siemens Aktiengesellschaft       NaN   \n",
       "54        NaT  VOW3.DE                                Volkswagen AG       NaN   \n",
       "\n",
       "   Announcement  \n",
       "0    2010-04-06  \n",
       "1    2015-03-09  \n",
       "2    2016-03-03  \n",
       "3    2018-05-03  \n",
       "4    2018-05-09  \n",
       "5    2019-04-09  \n",
       "6    2020-04-06  \n",
       "7    2020-08-19  \n",
       "8    2021-03-03  \n",
       "9    2021-10-26  \n",
       "10   2010-04-06  \n",
       "11   2012-05-09  \n",
       "12   2012-05-09  \n",
       "13   2015-03-09  \n",
       "14   2016-03-03  \n",
       "15   2018-05-03  \n",
       "16   2018-05-09  \n",
       "17   2019-04-09  \n",
       "18   2020-04-06  \n",
       "19   2020-08-19  \n",
       "20   2021-03-03  \n",
       "21   2021-10-26  \n",
       "22   2021-03-09  \n",
       "23   2021-03-09  \n",
       "24   2021-03-09  \n",
       "25   2021-03-09  \n",
       "26   2021-03-09  \n",
       "27   2021-03-09  \n",
       "28   2021-03-09  \n",
       "29   2021-03-09  \n",
       "30   2021-03-09  \n",
       "31   2021-03-09  \n",
       "32          NaT  \n",
       "33          NaT  \n",
       "34          NaT  \n",
       "35          NaT  \n",
       "36          NaT  \n",
       "37          NaT  \n",
       "38          NaT  \n",
       "39          NaT  \n",
       "40          NaT  \n",
       "41          NaT  \n",
       "42          NaT  \n",
       "43          NaT  \n",
       "44          NaT  \n",
       "45          NaT  \n",
       "46          NaT  \n",
       "47          NaT  \n",
       "48          NaT  \n",
       "49          NaT  \n",
       "50          NaT  \n",
       "51          NaT  \n",
       "52          NaT  \n",
       "53          NaT  \n",
       "54          NaT  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclusions = pd.read_csv('DAX_excluded_2010-2021.csv', sep = ';').rename(columns={'Ausgeschieden': 'Date'})\n",
    "exclusions['Type'] = 'Excluded'\n",
    "exclusions['Date'] = pd.to_datetime(exclusions['Date'])\n",
    "\n",
    "inclusions = pd.read_csv('DAX_included_2010-2021.csv', sep = ';').rename(columns={'Aufgenommen': 'Date'})\n",
    "inclusions['Type'] = 'Included'\n",
    "inclusions['Date'] = pd.to_datetime(inclusions['Date'])\n",
    "\n",
    "temp_rest = pd.read_csv('Companies_Ticker.csv', sep = ';')\n",
    "rest = temp_rest[temp_rest['Symbol'].isin(inclusions['Symbol']) == False]\n",
    "\n",
    "info_df = pd.concat([exclusions, inclusions, rest])\n",
    "info_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "announcements.rename(columns={'Date of change': 'Date', 'Date of announcement': 'Announcement'}, inplace=True)\n",
    "announcements['Date'] = pd.to_datetime(announcements['Date'])\n",
    "\n",
    "info_df = info_df.join(announcements.set_index('Date')['Announcement'], on='Date')\n",
    "info_df['Announcement'] = pd.to_datetime(info_df['Announcement'])\n",
    "info_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b62b208",
   "metadata": {},
   "source": [
    "## Creating Stockdata DataFrame <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e649b8a",
   "metadata": {},
   "source": [
    "* Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e096a61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADSGn.DE Close</th>\n",
       "      <th>ADSGn.DE Volume</th>\n",
       "      <th>AIRG.DE Close</th>\n",
       "      <th>AIRG.DE Volume</th>\n",
       "      <th>ALVG.DE Close</th>\n",
       "      <th>ALVG.DE Volume</th>\n",
       "      <th>BASFn.DE Close</th>\n",
       "      <th>BASFn.DE Volume</th>\n",
       "      <th>BAYGn.DE Close</th>\n",
       "      <th>BAYGn.DE Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>TKAG.DE Close</th>\n",
       "      <th>TKAG.DE Volume</th>\n",
       "      <th>VOWG.DE Close</th>\n",
       "      <th>VOWG.DE Volume</th>\n",
       "      <th>VNAn.DE Close</th>\n",
       "      <th>VNAn.DE Volume</th>\n",
       "      <th>WDIG.H Close</th>\n",
       "      <th>WDIG.H Volume</th>\n",
       "      <th>ZALG.DE Close</th>\n",
       "      <th>ZALG.DE Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-02</th>\n",
       "      <td>50</td>\n",
       "      <td>1975833</td>\n",
       "      <td>21,35</td>\n",
       "      <td>505206</td>\n",
       "      <td>145,92</td>\n",
       "      <td>2364687</td>\n",
       "      <td>50,47</td>\n",
       "      <td>4884954</td>\n",
       "      <td>60,472638</td>\n",
       "      <td>3605709,815</td>\n",
       "      <td>...</td>\n",
       "      <td>38,37</td>\n",
       "      <td>3766360</td>\n",
       "      <td>153,337349</td>\n",
       "      <td>1397017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,232</td>\n",
       "      <td>312,5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-03</th>\n",
       "      <td>50,09</td>\n",
       "      <td>1526879</td>\n",
       "      <td>21,4</td>\n",
       "      <td>480594</td>\n",
       "      <td>144,93</td>\n",
       "      <td>2602698</td>\n",
       "      <td>50,8</td>\n",
       "      <td>5039774</td>\n",
       "      <td>60,728502</td>\n",
       "      <td>4328600,389</td>\n",
       "      <td>...</td>\n",
       "      <td>38,3</td>\n",
       "      <td>3191220</td>\n",
       "      <td>150,833558</td>\n",
       "      <td>1813000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-04</th>\n",
       "      <td>49,81</td>\n",
       "      <td>1962837</td>\n",
       "      <td>20,78</td>\n",
       "      <td>472924</td>\n",
       "      <td>142,08</td>\n",
       "      <td>4449883</td>\n",
       "      <td>51,085</td>\n",
       "      <td>7035580</td>\n",
       "      <td>61,437051</td>\n",
       "      <td>6294868,89</td>\n",
       "      <td>...</td>\n",
       "      <td>36,58</td>\n",
       "      <td>5486575</td>\n",
       "      <td>148,200603</td>\n",
       "      <td>3535274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9,136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-07</th>\n",
       "      <td>49,51</td>\n",
       "      <td>1696299</td>\n",
       "      <td>19,17</td>\n",
       "      <td>1289394</td>\n",
       "      <td>140,06</td>\n",
       "      <td>4864778</td>\n",
       "      <td>52,1</td>\n",
       "      <td>7214856</td>\n",
       "      <td>62,490033</td>\n",
       "      <td>7140858,352</td>\n",
       "      <td>...</td>\n",
       "      <td>36,46</td>\n",
       "      <td>5012535</td>\n",
       "      <td>147,922404</td>\n",
       "      <td>2589606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8,528</td>\n",
       "      <td>792,5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3687 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ADSGn.DE Close ADSGn.DE Volume AIRG.DE Close AIRG.DE Volume  \\\n",
       "Date                                                                     \n",
       "2008-01-01            NaN             NaN           NaN            NaN   \n",
       "2008-01-02             50         1975833         21,35         505206   \n",
       "2008-01-03          50,09         1526879          21,4         480594   \n",
       "2008-01-04          49,81         1962837         20,78         472924   \n",
       "2008-01-07          49,51         1696299         19,17        1289394   \n",
       "...                   ...             ...           ...            ...   \n",
       "2020-01-01            NaN             NaN           NaN            NaN   \n",
       "2020-04-10            NaN             NaN           NaN            NaN   \n",
       "2020-04-13            NaN             NaN           NaN            NaN   \n",
       "2020-05-01            NaN             NaN           NaN            NaN   \n",
       "2020-06-01            NaN             NaN           NaN            NaN   \n",
       "\n",
       "           ALVG.DE Close ALVG.DE Volume BASFn.DE Close BASFn.DE Volume  \\\n",
       "Date                                                                     \n",
       "2008-01-01           NaN            NaN            NaN             NaN   \n",
       "2008-01-02        145,92        2364687          50,47         4884954   \n",
       "2008-01-03        144,93        2602698           50,8         5039774   \n",
       "2008-01-04        142,08        4449883         51,085         7035580   \n",
       "2008-01-07        140,06        4864778           52,1         7214856   \n",
       "...                  ...            ...            ...             ...   \n",
       "2020-01-01           NaN            NaN            NaN             NaN   \n",
       "2020-04-10           NaN            NaN            NaN             NaN   \n",
       "2020-04-13           NaN            NaN            NaN             NaN   \n",
       "2020-05-01           NaN            NaN            NaN             NaN   \n",
       "2020-06-01           NaN            NaN            NaN             NaN   \n",
       "\n",
       "           BAYGn.DE Close BAYGn.DE Volume  ... TKAG.DE Close TKAG.DE Volume  \\\n",
       "Date                                       ...                                \n",
       "2008-01-01            NaN             NaN  ...           NaN            NaN   \n",
       "2008-01-02      60,472638     3605709,815  ...         38,37        3766360   \n",
       "2008-01-03      60,728502     4328600,389  ...          38,3        3191220   \n",
       "2008-01-04      61,437051      6294868,89  ...         36,58        5486575   \n",
       "2008-01-07      62,490033     7140858,352  ...         36,46        5012535   \n",
       "...                   ...             ...  ...           ...            ...   \n",
       "2020-01-01            NaN             NaN  ...           NaN            NaN   \n",
       "2020-04-10            NaN             NaN  ...           NaN            NaN   \n",
       "2020-04-13            NaN             NaN  ...           NaN            NaN   \n",
       "2020-05-01            NaN             NaN  ...           NaN            NaN   \n",
       "2020-06-01            NaN             NaN  ...           NaN            NaN   \n",
       "\n",
       "           VOWG.DE Close VOWG.DE Volume VNAn.DE Close VNAn.DE Volume  \\\n",
       "Date                                                                   \n",
       "2008-01-01           NaN            NaN           NaN            NaN   \n",
       "2008-01-02    153,337349        1397017           NaN            NaN   \n",
       "2008-01-03    150,833558        1813000           NaN            NaN   \n",
       "2008-01-04    148,200603        3535274           NaN            NaN   \n",
       "2008-01-07    147,922404        2589606           NaN            NaN   \n",
       "...                  ...            ...           ...            ...   \n",
       "2020-01-01           NaN            NaN           NaN            NaN   \n",
       "2020-04-10           NaN            NaN           NaN            NaN   \n",
       "2020-04-13           NaN            NaN           NaN            NaN   \n",
       "2020-05-01           NaN            NaN           NaN            NaN   \n",
       "2020-06-01           NaN            NaN           NaN            NaN   \n",
       "\n",
       "           WDIG.H Close WDIG.H Volume ZALG.DE Close ZALG.DE Volume  \n",
       "Date                                                                \n",
       "2008-01-01          NaN           NaN           NaN            NaN  \n",
       "2008-01-02        9,232         312,5           NaN            NaN  \n",
       "2008-01-03        9,288           NaN           NaN            NaN  \n",
       "2008-01-04        9,136           NaN           NaN            NaN  \n",
       "2008-01-07        8,528         792,5           NaN            NaN  \n",
       "...                 ...           ...           ...            ...  \n",
       "2020-01-01          NaN           NaN           NaN            NaN  \n",
       "2020-04-10          NaN           NaN           NaN            NaN  \n",
       "2020-04-13          NaN           NaN           NaN            NaN  \n",
       "2020-05-01          NaN           NaN           NaN            NaN  \n",
       "2020-06-01          NaN           NaN           NaN            NaN  \n",
       "\n",
       "[3687 rows x 94 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockdata = pd.read_csv('stocks-historical-data.csv', sep = ';')\n",
    "stockdata = stockdata[1:]\n",
    "new_header = ['Date']\n",
    "temp_list = list(stockdata.columns)\n",
    "temp_list.remove('Unnamed: 0')\n",
    "\n",
    "for header in temp_list:\n",
    "    if '1' in header:\n",
    "        new_header.append(header[:-2] + ' Volume')\n",
    "    else:\n",
    "        new_header.append(str(header) + ' Close')\n",
    "\n",
    "stockdata.columns=new_header\n",
    "stockdata['Date'] = pd.to_datetime(stockdata['Date'], dayfirst=True)\n",
    "stockdata.set_index('Date', inplace=True)\n",
    "\n",
    "stockdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e802e9",
   "metadata": {},
   "source": [
    "## Creating Stockdata DataFrame (Yahoo finance backup) <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba77f1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>^GDAXI</th>\n",
       "      <th>ADS.DE</th>\n",
       "      <th>AIR.DE</th>\n",
       "      <th>ALV.DE</th>\n",
       "      <th>BAS.DE</th>\n",
       "      <th>BAYN.DE</th>\n",
       "      <th>BMW.DE</th>\n",
       "      <th>BNR.DE</th>\n",
       "      <th>BEI.DE</th>\n",
       "      <th>...</th>\n",
       "      <th>RWE.DE</th>\n",
       "      <th>SAP.DE</th>\n",
       "      <th>SRT3.DE</th>\n",
       "      <th>SIE.DE</th>\n",
       "      <th>ENR.DE</th>\n",
       "      <th>SHL.DE</th>\n",
       "      <th>SY1.DE</th>\n",
       "      <th>VOW3.DE</th>\n",
       "      <th>VNA.DE</th>\n",
       "      <th>ZAL.DE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>6048.299805</td>\n",
       "      <td>31.746376</td>\n",
       "      <td>11.494962</td>\n",
       "      <td>50.552078</td>\n",
       "      <td>25.849697</td>\n",
       "      <td>38.053692</td>\n",
       "      <td>20.743076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.848839</td>\n",
       "      <td>...</td>\n",
       "      <td>40.021980</td>\n",
       "      <td>27.285362</td>\n",
       "      <td>3.707397</td>\n",
       "      <td>41.060326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.520763</td>\n",
       "      <td>49.368145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>6031.859863</td>\n",
       "      <td>32.748112</td>\n",
       "      <td>11.412854</td>\n",
       "      <td>50.706219</td>\n",
       "      <td>25.457769</td>\n",
       "      <td>37.358742</td>\n",
       "      <td>20.911348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.638641</td>\n",
       "      <td>...</td>\n",
       "      <td>39.766632</td>\n",
       "      <td>27.041008</td>\n",
       "      <td>3.585296</td>\n",
       "      <td>41.085407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.524799</td>\n",
       "      <td>48.411404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>6034.330078</td>\n",
       "      <td>32.484276</td>\n",
       "      <td>11.490857</td>\n",
       "      <td>51.100182</td>\n",
       "      <td>25.619158</td>\n",
       "      <td>37.122589</td>\n",
       "      <td>21.234957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.608612</td>\n",
       "      <td>...</td>\n",
       "      <td>39.691181</td>\n",
       "      <td>27.521441</td>\n",
       "      <td>3.618596</td>\n",
       "      <td>41.235935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.928304</td>\n",
       "      <td>49.750843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>6019.359863</td>\n",
       "      <td>32.768715</td>\n",
       "      <td>11.589385</td>\n",
       "      <td>50.512100</td>\n",
       "      <td>25.449129</td>\n",
       "      <td>36.636799</td>\n",
       "      <td>21.422646</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.209644</td>\n",
       "      <td>...</td>\n",
       "      <td>39.522873</td>\n",
       "      <td>28.250376</td>\n",
       "      <td>3.516477</td>\n",
       "      <td>41.725117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.839533</td>\n",
       "      <td>50.324905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>6037.609863</td>\n",
       "      <td>32.649170</td>\n",
       "      <td>11.778231</td>\n",
       "      <td>50.238041</td>\n",
       "      <td>25.371321</td>\n",
       "      <td>36.312939</td>\n",
       "      <td>21.134636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.077118</td>\n",
       "      <td>...</td>\n",
       "      <td>39.464832</td>\n",
       "      <td>28.449173</td>\n",
       "      <td>3.529796</td>\n",
       "      <td>41.988529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.960585</td>\n",
       "      <td>50.868324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076.0</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>14693.000000</td>\n",
       "      <td>223.050003</td>\n",
       "      <td>114.019997</td>\n",
       "      <td>206.600006</td>\n",
       "      <td>65.269997</td>\n",
       "      <td>52.410000</td>\n",
       "      <td>90.930000</td>\n",
       "      <td>76.419998</td>\n",
       "      <td>86.720001</td>\n",
       "      <td>...</td>\n",
       "      <td>37.790001</td>\n",
       "      <td>100.059998</td>\n",
       "      <td>388.600006</td>\n",
       "      <td>132.039993</td>\n",
       "      <td>18.126492</td>\n",
       "      <td>53.080002</td>\n",
       "      <td>102.300003</td>\n",
       "      <td>188.699997</td>\n",
       "      <td>45.990002</td>\n",
       "      <td>57.939999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3077.0</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>14631.360352</td>\n",
       "      <td>217.899994</td>\n",
       "      <td>113.779999</td>\n",
       "      <td>206.350006</td>\n",
       "      <td>64.860001</td>\n",
       "      <td>52.950001</td>\n",
       "      <td>91.620003</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>88.459999</td>\n",
       "      <td>...</td>\n",
       "      <td>37.540001</td>\n",
       "      <td>99.599998</td>\n",
       "      <td>386.899994</td>\n",
       "      <td>131.539993</td>\n",
       "      <td>18.051878</td>\n",
       "      <td>53.779999</td>\n",
       "      <td>102.699997</td>\n",
       "      <td>187.080002</td>\n",
       "      <td>45.709999</td>\n",
       "      <td>56.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078.0</th>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>14052.099609</td>\n",
       "      <td>210.149994</td>\n",
       "      <td>108.900002</td>\n",
       "      <td>200.199997</td>\n",
       "      <td>61.060001</td>\n",
       "      <td>50.599998</td>\n",
       "      <td>84.989998</td>\n",
       "      <td>71.559998</td>\n",
       "      <td>86.559998</td>\n",
       "      <td>...</td>\n",
       "      <td>37.709999</td>\n",
       "      <td>97.480003</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>124.180000</td>\n",
       "      <td>19.385000</td>\n",
       "      <td>53.900002</td>\n",
       "      <td>102.900002</td>\n",
       "      <td>176.100006</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>55.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079.0</th>\n",
       "      <td>2022-02-25</td>\n",
       "      <td>14567.230469</td>\n",
       "      <td>213.850006</td>\n",
       "      <td>115.980003</td>\n",
       "      <td>207.449997</td>\n",
       "      <td>60.430000</td>\n",
       "      <td>52.880001</td>\n",
       "      <td>88.019997</td>\n",
       "      <td>75.220001</td>\n",
       "      <td>89.660004</td>\n",
       "      <td>...</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>101.400002</td>\n",
       "      <td>388.299988</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>19.434999</td>\n",
       "      <td>55.320000</td>\n",
       "      <td>105.550003</td>\n",
       "      <td>185.320007</td>\n",
       "      <td>46.779999</td>\n",
       "      <td>55.959999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080.0</th>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>14461.019531</td>\n",
       "      <td>212.050003</td>\n",
       "      <td>115.160004</td>\n",
       "      <td>203.300003</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>51.509998</td>\n",
       "      <td>86.559998</td>\n",
       "      <td>74.879997</td>\n",
       "      <td>90.419998</td>\n",
       "      <td>...</td>\n",
       "      <td>41.490002</td>\n",
       "      <td>101.320000</td>\n",
       "      <td>394.200012</td>\n",
       "      <td>126.660004</td>\n",
       "      <td>21.430000</td>\n",
       "      <td>57.480000</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>178.039993</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>59.580002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3142 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date        ^GDAXI      ADS.DE      AIR.DE      ALV.DE  \\\n",
       "0.0    2010-01-04   6048.299805   31.746376   11.494962   50.552078   \n",
       "1.0    2010-01-05   6031.859863   32.748112   11.412854   50.706219   \n",
       "2.0    2010-01-06   6034.330078   32.484276   11.490857   51.100182   \n",
       "3.0    2010-01-07   6019.359863   32.768715   11.589385   50.512100   \n",
       "4.0    2010-01-08   6037.609863   32.649170   11.778231   50.238041   \n",
       "...           ...           ...         ...         ...         ...   \n",
       "3076.0 2022-02-22  14693.000000  223.050003  114.019997  206.600006   \n",
       "3077.0 2022-02-23  14631.360352  217.899994  113.779999  206.350006   \n",
       "3078.0 2022-02-24  14052.099609  210.149994  108.900002  200.199997   \n",
       "3079.0 2022-02-25  14567.230469  213.850006  115.980003  207.449997   \n",
       "3080.0 2022-02-28  14461.019531  212.050003  115.160004  203.300003   \n",
       "\n",
       "           BAS.DE    BAYN.DE     BMW.DE     BNR.DE     BEI.DE  ...     RWE.DE  \\\n",
       "0.0     25.849697  38.053692  20.743076        NaN  39.848839  ...  40.021980   \n",
       "1.0     25.457769  37.358742  20.911348        NaN  39.638641  ...  39.766632   \n",
       "2.0     25.619158  37.122589  21.234957        NaN  39.608612  ...  39.691181   \n",
       "3.0     25.449129  36.636799  21.422646        NaN  39.209644  ...  39.522873   \n",
       "4.0     25.371321  36.312939  21.134636        NaN  38.077118  ...  39.464832   \n",
       "...           ...        ...        ...        ...        ...  ...        ...   \n",
       "3076.0  65.269997  52.410000  90.930000  76.419998  86.720001  ...  37.790001   \n",
       "3077.0  64.860001  52.950001  91.620003  76.000000  88.459999  ...  37.540001   \n",
       "3078.0  61.060001  50.599998  84.989998  71.559998  86.559998  ...  37.709999   \n",
       "3079.0  60.430000  52.880001  88.019997  75.220001  89.660004  ...  40.000000   \n",
       "3080.0  59.250000  51.509998  86.559998  74.879997  90.419998  ...  41.490002   \n",
       "\n",
       "            SAP.DE     SRT3.DE      SIE.DE     ENR.DE     SHL.DE      SY1.DE  \\\n",
       "0.0      27.285362    3.707397   41.060326        NaN        NaN   12.520763   \n",
       "1.0      27.041008    3.585296   41.085407        NaN        NaN   12.524799   \n",
       "2.0      27.521441    3.618596   41.235935        NaN        NaN   12.928304   \n",
       "3.0      28.250376    3.516477   41.725117        NaN        NaN   12.839533   \n",
       "4.0      28.449173    3.529796   41.988529        NaN        NaN   12.960585   \n",
       "...            ...         ...         ...        ...        ...         ...   \n",
       "3076.0  100.059998  388.600006  132.039993  18.126492  53.080002  102.300003   \n",
       "3077.0   99.599998  386.899994  131.539993  18.051878  53.779999  102.699997   \n",
       "3078.0   97.480003  383.000000  124.180000  19.385000  53.900002  102.900002   \n",
       "3079.0  101.400002  388.299988  129.720001  19.434999  55.320000  105.550003   \n",
       "3080.0  101.320000  394.200012  126.660004  21.430000  57.480000  106.500000   \n",
       "\n",
       "           VOW3.DE     VNA.DE     ZAL.DE  \n",
       "0.0      49.368145        NaN        NaN  \n",
       "1.0      48.411404        NaN        NaN  \n",
       "2.0      49.750843        NaN        NaN  \n",
       "3.0      50.324905        NaN        NaN  \n",
       "4.0      50.868324        NaN        NaN  \n",
       "...            ...        ...        ...  \n",
       "3076.0  188.699997  45.990002  57.939999  \n",
       "3077.0  187.080002  45.709999  56.000000  \n",
       "3078.0  176.100006  44.410000  55.500000  \n",
       "3079.0  185.320007  46.779999  55.959999  \n",
       "3080.0  178.039993  47.500000  59.580002  \n",
       "\n",
       "[3142 rows x 42 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Get data from yahoo finance.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":data_joined:  df\n",
    "    Contains Adj CLose for all stocks.\n",
    "-------\n",
    "'''\n",
    "tickers = pd.read_csv('Companies_Ticker.csv', sep = ';')\n",
    "\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2022-03-01'\n",
    "i = 0\n",
    "\n",
    "for key in tickers['Symbol']:\n",
    "    data = yf.download(tickers['Symbol'][i], start=start_date, end=end_date, progress=False)\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop(['High', 'Low', 'Open', 'Close', 'Volume'], axis = 1, inplace=True)\n",
    "    data.rename(columns={'Adj Close': tickers['Symbol'][i]}, inplace=True)\n",
    "    \n",
    "    if i > 0:\n",
    "        data_joined = data_joined.join(data.set_index('Date'), on='Date', how='outer')\n",
    "    else:\n",
    "        data_joined = data\n",
    "    i += 1\n",
    "\n",
    "data_joined.sort_values(by='Date', inplace=True)   \n",
    "data_joined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e253fea",
   "metadata": {},
   "source": [
    "## To be deleted, wenn alle analysne angepasst sind <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da14e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Pulls time series data for stocks on a daily basis from 2010-01-01 until 2022-03-01.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_dict:  dict\n",
    "    Contains the stock symbols as key and the time series as values.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stock_dict = {}\n",
    "for s in stock_data['Symbol']: # iterate for every stock indices\n",
    "    # Retrieve data from Yahoo Finance\n",
    "    tickerData = yf.Ticker(s)\n",
    "    # Save historical data \n",
    "    stock_dict[s] = yf.download(s, start='2010-01-01', end='2022-03-01', progress=False)\n",
    "# Concatenate all data\n",
    "stocks_as_df = pd.concat(stock_dict, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8196340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Pulls time series data for stocks on a daily basis from 2009-06-21 until 2022-03-01.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_included:  dict\n",
    "    Contains the stock symbols as key and the time series as values.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stock_included = {}\n",
    "for s in DAX_included['Symbol']: # iterate for every stock indices\n",
    "    # Retrieve data from Yahoo Finance\n",
    "    tickerData = yf.Ticker(s)\n",
    "    # Save historical data \n",
    "    stock_included[s] = yf.download(s, start='2009-06-21', end='2022-03-01', progress=False)\n",
    "stock_included_as_df = pd.concat(stock_included, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "379c73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Pulls time series data for stocks on a daily basis from 2009-06-21 until 2022-03-01.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_included:  dict\n",
    "    Contains the stock symbols as key and the time series as values.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stock_excluded = {}\n",
    "for s in DAX_excluded['Symbol']: # iterate for every stock indices\n",
    "    # Retrieve data from Yahoo Finance\n",
    "    tickerData = yf.Ticker(s)\n",
    "    # Save historical data \n",
    "    stock_excluded[s] = yf.download(s, start='2009-06-21', end='2022-03-01', progress=False)\n",
    "stock_excluded_as_df = pd.concat(stock_excluded, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238db965",
   "metadata": {},
   "source": [
    "## Calculate Daily Returns(to be deleted) <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "143c84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Transform daily price data to daily returns.\n",
    "Parameters\n",
    "----------\n",
    ":returns_daily:  dict\n",
    "    Contains the stock symbols as key and the daily returns as values.\n",
    ":returns_daily_excluded: dict\n",
    "    Contains the stock symbols as key and the daily returns as values.\n",
    ":returns_daily_included: dict\n",
    "    Contains the stock symbols as key and the daily returns as values.\n",
    ":benchmark: df\n",
    "    Contains daily returns from the benchmark.\n",
    "-------\n",
    "'''\n",
    "returns_daily = {}\n",
    "for s in stock_data['Symbol']:\n",
    "    returns_daily[s] = stock_dict[s]['Adj Close'].pct_change()\n",
    "returns_daily_included = {}\n",
    "for s in DAX_included['Symbol']:\n",
    "    returns_daily_included[s] = stock_included[s]['Adj Close'].pct_change()\n",
    "DAX_included['Aufgenommen'] = pd.to_datetime(DAX_included['Aufgenommen'], format='%d.%m.%Y')\n",
    "\n",
    "returns_daily_excluded = {}\n",
    "for s in DAX_excluded['Symbol']:\n",
    "    returns_daily_excluded[s] = stock_excluded[s]['Adj Close'].pct_change()\n",
    "DAX_excluded['Ausgeschieden'] = pd.to_datetime(DAX_excluded['Ausgeschieden'], format='%d.%m.%Y')\n",
    "    \n",
    "benchmark['Umtauschdatum'] = pd.to_datetime(benchmark['Umtauschdatum'], format='%d.%m.%y')\n",
    "benchmark = pd.DataFrame(benchmark['Schlusskurs'].astype(float).pct_change()).set_index(benchmark['Umtauschdatum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2719f35",
   "metadata": {},
   "source": [
    "## Data Quality Checks (needs to be updated) <a class=\"anchor\" id=\"3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80afc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check if stocks_as_df contains NA or zeros in Volume & Adjusted Close.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stocks_as_df:  df\n",
    "    Contains the time series data as one df.\n",
    ":stocks_as_df_Volume_is_0:  df\n",
    "    Contains the rows where Volume == 0.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stocks_as_df_has_nan = np.isnan(np.sum(stocks_as_df)) #no NAs\n",
    "\n",
    "#(stocks_as_df < 0).any()\n",
    "#(stocks_as_df = 0).any()\n",
    "\n",
    "stocks_as_df_Volume_is_0 = stocks_as_df.loc[stocks_as_df[\"Volume\"] == 0] #2774 times 0\n",
    "stocks_as_df_AdjClose_is_0 = stocks_as_df.loc[stocks_as_df[\"Adj Close\"] == 0] #never 0\n",
    "\n",
    "#stock_dict['ZAL.DE'] #spot the 0 for '2014-10-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Interpolate Volume using 'spline'.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_dict_replaced_all:  dict\n",
    "    Contains the time series data as stock_dict but with interpolated values for 'Volume'.\n",
    "\n",
    ":stock_dict_replaced:  dict\n",
    "    Contains the time series data as stock_dict but with interpolated values for 'Volume' only when 'Close' is not equal to 'Open'.\n",
    "-------\n",
    "'''\n",
    "#stock_dict_replaced_all = stock_dict\n",
    "#for key in stock_dict_replaced_all:\n",
    "#    stock_dict_replaced_all[key].loc[stock_dict_replaced_all[key]['Volume'] == 0, 'Volume'] = np.nan\n",
    "#    stock_dict_replaced_all[key]['Volume'].interpolate(method ='spline', order = 2, inplace=True)\n",
    "\n",
    "#stock_dict_replaced_all['^GDAXI'].loc[:'2018-04-27'] #<- should now have an interpolated value at '2018-04-27'\n",
    "#stock_dict_replaced_all['ZAL.DE'].loc[:'2017-06-05'] #<- should now have interpolated value at '2017-06-05'\n",
    "\n",
    "stock_dict_replaced = stock_dict\n",
    "for key in stock_dict_replaced:\n",
    "    stock_dict_replaced[key].loc[(stock_dict_replaced[key]['Volume'] == 0) & (stock_dict_replaced[key]['Open'] != stock_dict_replaced[key]['Close']), 'Volume'] = np.nan\n",
    "    stock_dict_replaced[key]['Volume'].interpolate(method ='spline', order = 2, inplace=True)\n",
    "\n",
    "#stock_dict_replaced['^GDAXI'].loc[:'2018-04-27'] #<- should now have an interpolated value at '2018-04-27'\n",
    "#stock_dict_replaced['ZAL.DE'].loc[:'2017-06-05'] #<- should now NOT have interpolated value at '2017-06-05'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13853365",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check date index (to be deleted when stock_dict is out of use)\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":dates:  df\n",
    "    Contains the 'Date' index from each stock. \n",
    "-------\n",
    "'''\n",
    "\n",
    "stock_dict_check_idx = stock_dict\n",
    "\n",
    "dates = pd.DataFrame()\n",
    "\n",
    "for key in stock_dict_check_idx:\n",
    "    stock_dict_check_idx[key].reset_index(inplace=True)\n",
    "    dates[key] = stock_dict_check_idx[key]['Date']\n",
    "\n",
    "#dates.to_excel(\"dates.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de66a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check if Adj Close in stocks_as_df differs from previous/ following day.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stocks_as_df:  df\n",
    "    Contains the time series data as one df.\n",
    ":stocks_as_df_adjclose_peak_bottom:  dataframe\n",
    "    Contains the rows where Adj. Close differs\n",
    "-------\n",
    "'''\n",
    "stocks_as_df_adjclose_peak_bottom_list = []\n",
    "n = 1\n",
    "\n",
    "while n < len(stocks_as_df)-1:\n",
    "    if abs(stocks_as_df['Adj Close'][n] -\n",
    "           statistics.mean([stocks_as_df['Adj Close'][n-1],\n",
    "                            stocks_as_df['Adj Close'][n+1]])) > .5 * stocks_as_df['Adj Close'][n]:\n",
    "        stocks_as_df_adjclose_peak_bottom_list.append(stocks_as_df.iloc[n])\n",
    "\n",
    "    n += 1\n",
    "\n",
    "stocks_as_df_adjclose_peak_bottom = pd.DataFrame(stocks_as_df_adjclose_peak_bottom_list) #29 times "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9b548",
   "metadata": {},
   "source": [
    "## Descriptive Statistics of the whole Dataset (needs to be updated) <a class=\"anchor\" id=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculating measures of location, statistical dispersion and shape.\n",
    "Parameters\n",
    "----------\n",
    ":des_stat:  dataframe\n",
    "    Contains the descriptive statistics.\n",
    "-------\n",
    "'''\n",
    "\n",
    "des_stat = pd.DataFrame(columns=stock_data['Symbol'], \n",
    "                        index=['Observations', 'NAs', 'Minimum', 'Quartile 1', 'Median', \n",
    "                               'Artithmetic Mean', 'Geometric Mean', 'Quartile 3', 'Maximum', 'SE Mean',\n",
    "                               'LCL Mean (.95)', 'UCL Mean (.95)', 'Variance', 'Stdev', 'Skewness','Kurtosis'])\n",
    "\n",
    "for s in stock_data['Symbol']:\n",
    "    df = pd.DataFrame(returns_daily[s])\n",
    "    des_stat[s] = pat.stats_table(df, manager_col=0)\n",
    "des_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74165ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Calculating the downside statistics.\n",
    "Parameters\n",
    "----------\n",
    ":down_stat:  dataframe\n",
    "    Contains the downside statistics.\n",
    "-------\n",
    "'''\n",
    "#down_stat = pd.DataFrame(columns=stock_data['Symbol'], \n",
    "#                        index=['Semi Deviation', 'Gain Deviation', 'Loss Deviation', 'Downside Deviation (MAR=2.0%)',\n",
    "#                               'Downside Deviation (rf=0.5%)', 'Downside Deviation (0%)', 'Maximum Drawdown', \n",
    "#                               'Historical VaR (95%)', 'Historical ES (95%)', 'Modified VaR (95%)', 'Modified ES (95%)'])\n",
    "\n",
    "#for s in stock_data['Symbol']:\n",
    "#    df = pd.DataFrame(returns_daily[s])\n",
    "#    down_stat[s] = pat.create_downside_table(df,0)\n",
    "#down_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e4cd9",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Price Pressure <a class=\"anchor\" id=\"5-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all dicts into a single one\n",
    "stock_dict = {**stock_dict, **stock_included, **stock_excluded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8864b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def calc_mvr_multiple_days(year_start, year_end, inclusions, day_range, stocks, market_symbol):\n",
    "    \"\"\"\n",
    "    Calculates MVR measures and takes the average over multiple days.\n",
    "        \n",
    "    :param year_start:\n",
    "        year in which to start checking for inclusions to the index\n",
    "    :param year_end:\n",
    "        year in which to end checking for inclusions to the index\n",
    "    :param inclusions:\n",
    "        dataframe showing inclusions to an index\n",
    "        Needed columns:\n",
    "            Aufgenommen - Date included to the index\n",
    "            Symbol - stock's symbol\n",
    "    :param day_range:\n",
    "        range of days for \"event period\" i\n",
    "    :param stock:\n",
    "        stock data for the entire time horizon\n",
    "    :param market_symbol:\n",
    "        stock symbol for the market for the entire time horizon\n",
    "        \n",
    "    :return:\n",
    "        mean, stddev, N of all Volume Ratios of included stocks in the selected time period\n",
    "    \"\"\"\n",
    "    s = pd.Series([], dtype='float64')\n",
    "    for i in day_range:\n",
    "        s_, _, _, n = calc_mvr(year_start, year_end, inclusions, i, stocks, market_symbol)\n",
    "        s.append(s_)\n",
    "    return s, s.mean(), s.std(), n\n",
    "    \n",
    "\n",
    "def calc_mvr(year_start, year_end, inclusions, day, stocks, market_symbol):\n",
    "    \"\"\"\n",
    "    MVR of stock i is the mean VR (Volume Ratio) for event period t\n",
    "    VR of stock i is the ratio of Volume of stock i traded in period t to volume traded in the market times volume traded \n",
    "        in the market over the past 8 weeks over volume of stock i in the past 8 weeks\n",
    "        \n",
    "    :param year_start:\n",
    "        year in which to start checking for inclusions to the index\n",
    "    :param year_end:\n",
    "        year in which to end checking for inclusions to the index\n",
    "    :param inclusions:\n",
    "        dataframe showing inclusions to an index\n",
    "        Needed columns:\n",
    "            Aufgenommen - Date included to the index\n",
    "            Symbol - stock's symbol\n",
    "    :param day:\n",
    "        how many days after the announcement date is the \"event period\" i?\n",
    "    :param stock:\n",
    "        stock data for the entire time horizon\n",
    "    :param market_symbol:\n",
    "        stock symbol for the market for the entire time horizon\n",
    "        \n",
    "    :return:\n",
    "        series (the series of VRs), mean, stddev, N of all Volume Ratios of included stocks in the selected time period\n",
    "    \"\"\"\n",
    "    \n",
    "    year_start = datetime.strptime('01.01.' + str(year_start), '%d.%m.%Y')\n",
    "    year_end = datetime.strptime('31.12.' + str(year_end), '%d.%m.%Y')\n",
    "    \n",
    "    inclusions_in_time_period = inclusions[(inclusions['Aufgenommen'] >= year_start) & (inclusions['Aufgenommen'] <= year_end)]\n",
    "    \n",
    "    apply_calc_vr = lambda row: calc_vr(row['Aufgenommen'], day, stocks[row['Symbol']], stocks[market_symbol])\n",
    "    vr_series = inclusions_in_time_period.apply(apply_calc_vr, axis=1)\n",
    "    return vr_series, vr_series.mean(), vr_series.std(), vr_series.size\n",
    "    \n",
    "    \n",
    "def calc_vr(announcement_date, day, stock, market):\n",
    "    \"\"\"\n",
    "    VR of stock i is the ratio of Volume of stock i traded in period t to volume traded in the market times volume traded \n",
    "        in the market over the past 8 weeks over volume of stock i in the past 8 weeks\n",
    "    $ VR_{it} = \\frac{V_{it}}{V_{mt}} * \\frac{V_m}{V_i} $\n",
    "    \n",
    "    :param announcement_date:\n",
    "        the announcement date\n",
    "    :param day:\n",
    "        how many days after the announcement date is the \"event period\" i?\n",
    "    :param stock:\n",
    "        stock data for the entire time horizon\n",
    "    :param market:\n",
    "        stock data for the market for the entire time horizon\n",
    "    \"\"\"\n",
    "    \n",
    "    start_date = announcement_date - timedelta(weeks=8)\n",
    "    i = announcement_date + timedelta(days=day)\n",
    "    \n",
    "    i_slice = stock[(stock.index >= start_date) & (stock.index <= i)]\n",
    "    m_slice = market[(market.index >= start_date) & (market.index <= i)]\n",
    "    \n",
    "    v_it = stock[stock.index == i]['Volume'].values[0]\n",
    "    v_mt = market[market.index == i]['Volume'].values[0]\n",
    "    \n",
    "    v_i = np.mean(i_slice['Volume'])\n",
    "    v_m = np.mean(m_slice['Volume'])\n",
    "    \n",
    "    return (v_it / v_mt) * (v_m / v_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mvr_multiple_days(2010, 2013, DAX_included,  range(1, 6), stock_dict, '^GDAXI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "year_ranges = [(2010, 2021), (2010, 2015), (2016, 2021)]\n",
    "year_ranges += [(x, x) for x in range(2010, 2022)]\n",
    "\n",
    "df = pd.DataFrame(columns=['N', 'MVR Day 1', 'STD Day 1', 't Day 1', '% > 1 Day 1', 'MVR Day 1-5', 'STD Day 1-5', 't Day 1-5', '% > 1 Day 1-5'])\n",
    "\n",
    "for (y1, y2) in year_ranges:\n",
    "    s, m, stdev, n = calc_mvr(y1, y2, DAX_included, 1, stock_dict, '^GDAXI')\n",
    "    t = scipy.stats.testt_1samp(series, 1)\n",
    "    p = s.gt(1).sum() / s.size\n",
    "    d = {'N': n, 'MVR Day 1': m, 'STD Day 1': stdev, 't Day 1': t, '% > 1 Day 1': p}\n",
    "    s, m, stdev, _ = calc_mvr_multiple_days(y1, y2, DAX_included, range(1, 6), stock_dict, '^GDAXI')\n",
    "    d['MVR Day 1-5'] = m\n",
    "    d['STD Day 1-5'] = stdev\n",
    "    d['t Day 1-5'] = scipy.stats.testt_1samp(s, 1)\n",
    "    d['% > 1 Day 1-5'] = s.gt(1).sum() / s.size\n",
    "    df = df.append(pd.DataFrame(data=d, index=[str(y1) if y1 == y2 else str(y1) + '-' + str(y2)]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85beec6f",
   "metadata": {},
   "source": [
    "__To-Do's__\n",
    "* Welche Index Inklusion Effekte gibt es.\n",
    "* Gibt es einen Pre-announcement drift? \n",
    "* Gibt es sonstige Announcement Effekte?\n",
    "\n",
    "__Paper 1 EMH vs. PPH nachbauen__\n",
    "* Alle Aktien für die Analyse zusammen suchen - bisher sind nur die neusten 40 enthalten (Sophie hat hier schon eine CSV vorbereitet).\n",
    "*    Analyse excess return & trading volume on the first 5 days with the cross sectional means.\n",
    "*    Analysis before and after annoucment as well as after the inclusion day\n",
    "\n",
    "* Vorschläge hierzu von Stefan:\n",
    "    * Alles Herausnahmen und Hereinnahmen in den DAX zusammennehmen, da nur so statistische Test möglich sind\n",
    "    * Bspw. vor 2010, nach 2010 Veränderungen anschauen\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb718155",
   "metadata": {},
   "source": [
    "Änderungsvorschläge von Stefan\n",
    "\t•\tAlles Änderungen zusammen (30 auf 40)\n",
    "--> inferenzen, statistischen tests nur so möglich\n",
    "\t•\tVor 2010, nach 2010\n",
    "\t•\tÜberlegen, wie wir das empirisch machen --> counterfactual\n",
    "\t•\tAbnormal returns, worauf basiert es; was ist expected return; komplexeres modell\n",
    "\t•\tIndex Inklusion Effekte\n",
    "\t•\tFreiheitsgrade im empirischen Ansatz, solange die Frage beantwortet wird wie sich Inklusion auf Expected Returns und andere Metriken auswirkt\n",
    "\t•\tAbnormal returns; Volatilität; Handelsvolumen (ETFs müssen sie nun auch handeln); Investors attention (das sollten wir absprechen; ggf. Aufnahme in Index als Maß für Attention; dazu: googeln)\n",
    "\t•\tKorrelationen: Wie ändern sich Korrelation (das könnte attention sein) --> ökonomisch bedeutsam, weil systematisches Risiko\n",
    "\t•\tGgf. Datenfiltern; Daten Fehler; für Preise funktioniert gut; Handelsvolumen nicht so zuverlässig für damals\n",
    "\t•\tWichtig, dass Tage stimmen, ansonsten problematisch\n",
    "\t•\tAnnouncement day & inclusion day\n",
    "\t•\tPre-announcement drift\n",
    "\t•\tAnnouncement Effekte\n",
    "\t•\tDividends announcements --> Literatur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9cc78",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Correlation Analysis <a class=\"anchor\" id=\"6-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3155f94",
   "metadata": {},
   "source": [
    "In this Part, we'll have a closer look onto the correlation of a stock before and after inclusion/exclusion with the index itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e810b6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Type</th>\n",
       "      <th>30 -&gt; 40</th>\n",
       "      <th>Corr_before</th>\n",
       "      <th>Corr_after</th>\n",
       "      <th>Delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LXS.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.800405</td>\n",
       "      <td>0.468043</td>\n",
       "      <td>-0.332362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BEI.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.604934</td>\n",
       "      <td>0.318893</td>\n",
       "      <td>-0.286041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LHA.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.754511</td>\n",
       "      <td>0.487113</td>\n",
       "      <td>-0.267398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DWNI.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.450306</td>\n",
       "      <td>0.242293</td>\n",
       "      <td>-0.208013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CON.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.846636</td>\n",
       "      <td>0.657267</td>\n",
       "      <td>-0.189370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DHER.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.359501</td>\n",
       "      <td>0.174265</td>\n",
       "      <td>-0.185237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PSM.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.740038</td>\n",
       "      <td>0.639269</td>\n",
       "      <td>-0.100769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PSM.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.403081</td>\n",
       "      <td>0.314127</td>\n",
       "      <td>-0.088954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SZG.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.752604</td>\n",
       "      <td>0.671941</td>\n",
       "      <td>-0.080663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WDI.HM</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.138840</td>\n",
       "      <td>0.071607</td>\n",
       "      <td>-0.067234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HEI.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.761874</td>\n",
       "      <td>0.696884</td>\n",
       "      <td>-0.064990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WDI.HM</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.452377</td>\n",
       "      <td>0.406548</td>\n",
       "      <td>-0.045829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ENR.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.403663</td>\n",
       "      <td>0.390104</td>\n",
       "      <td>-0.013559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BEI.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.350908</td>\n",
       "      <td>0.384886</td>\n",
       "      <td>0.033977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POAHY</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.529783</td>\n",
       "      <td>0.569102</td>\n",
       "      <td>0.039319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SHL.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.336531</td>\n",
       "      <td>0.387496</td>\n",
       "      <td>0.050965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LXS.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.715348</td>\n",
       "      <td>0.779815</td>\n",
       "      <td>0.064467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ZAL.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.216910</td>\n",
       "      <td>0.286520</td>\n",
       "      <td>0.069610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AIR.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.623178</td>\n",
       "      <td>0.722612</td>\n",
       "      <td>0.099434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MTX.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.579545</td>\n",
       "      <td>0.685125</td>\n",
       "      <td>0.105580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CBK.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.475756</td>\n",
       "      <td>0.583274</td>\n",
       "      <td>0.107518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VNA.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.482946</td>\n",
       "      <td>0.611064</td>\n",
       "      <td>0.128118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PUM.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.475405</td>\n",
       "      <td>0.609208</td>\n",
       "      <td>0.133804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BNR.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.532324</td>\n",
       "      <td>0.680033</td>\n",
       "      <td>0.147708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1COV.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>False</td>\n",
       "      <td>0.507237</td>\n",
       "      <td>0.670537</td>\n",
       "      <td>0.163299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDF.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.431357</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>0.176982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>QIA.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.049532</td>\n",
       "      <td>0.135059</td>\n",
       "      <td>0.184591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TKA.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.516402</td>\n",
       "      <td>0.731608</td>\n",
       "      <td>0.215206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SRT3.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.013312</td>\n",
       "      <td>0.241314</td>\n",
       "      <td>0.228002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SY1.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>0.133508</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>0.295834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HFG.DE</td>\n",
       "      <td>Included</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.059201</td>\n",
       "      <td>0.247999</td>\n",
       "      <td>0.307199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DWNI.DE</td>\n",
       "      <td>Excluded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.064769</td>\n",
       "      <td>0.530200</td>\n",
       "      <td>0.465431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ticker      Type  30 -> 40  Corr_before  Corr_after     Delta\n",
       "2    LXS.DE  Included     False     0.800405    0.468043 -0.332362\n",
       "11   BEI.DE  Excluded     False     0.604934    0.318893 -0.286041\n",
       "8    LHA.DE  Excluded     False     0.754511    0.487113 -0.267398\n",
       "14  DWNI.DE  Included     False     0.450306    0.242293 -0.208013\n",
       "16   CON.DE  Included     False     0.846636    0.657267 -0.189370\n",
       "20  DHER.DE  Included     False     0.359501    0.174265 -0.185237\n",
       "5    PSM.DE  Included     False     0.740038    0.639269 -0.100769\n",
       "4    PSM.DE  Excluded     False     0.403081    0.314127 -0.088954\n",
       "0    SZG.DE  Excluded     False     0.752604    0.671941 -0.080663\n",
       "9    WDI.HM  Excluded     False     0.138840    0.071607 -0.067234\n",
       "15   HEI.DE  Included     False     0.761874    0.696884 -0.064990\n",
       "10   WDI.HM  Included     False     0.452377    0.406548 -0.045829\n",
       "21   ENR.DE  Included     False     0.403663    0.390104 -0.013559\n",
       "12   BEI.DE  Included     False     0.350908    0.384886  0.033977\n",
       "25    POAHY  Included      True     0.529783    0.569102  0.039319\n",
       "29   SHL.DE  Included      True     0.336531    0.387496  0.050965\n",
       "1    LXS.DE  Excluded     False     0.715348    0.779815  0.064467\n",
       "31   ZAL.DE  Included      True     0.216910    0.286520  0.069610\n",
       "22   AIR.DE  Included      True     0.623178    0.722612  0.099434\n",
       "19   MTX.DE  Included     False     0.579545    0.685125  0.105580\n",
       "6    CBK.DE  Excluded     False     0.475756    0.583274  0.107518\n",
       "17   VNA.DE  Included     False     0.482946    0.611064  0.128118\n",
       "26   PUM.DE  Included      True     0.475405    0.609208  0.133804\n",
       "23   BNR.DE  Included      True     0.532324    0.680033  0.147708\n",
       "18  1COV.DE  Included     False     0.507237    0.670537  0.163299\n",
       "3    SDF.DE  Excluded     False     0.431357    0.608339  0.176982\n",
       "27   QIA.DE  Included      True    -0.049532    0.135059  0.184591\n",
       "7    TKA.DE  Excluded     False     0.516402    0.731608  0.215206\n",
       "28  SRT3.DE  Included      True     0.013312    0.241314  0.228002\n",
       "30   SY1.DE  Included      True     0.133508    0.429342  0.295834\n",
       "24   HFG.DE  Included      True    -0.059201    0.247999  0.307199\n",
       "13  DWNI.DE  Excluded     False     0.064769    0.530200  0.465431"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = returns_daily_included\n",
    "data.update(returns_daily_excluded)\n",
    "dax = returns_daily['^GDAXI']\n",
    "unique_stocks = list(dict.fromkeys(list(info_df.loc[~info_df['Type'].isnull()]['Symbol'])))\n",
    "\n",
    "corr_df_list = []\n",
    "for s in unique_stocks:\n",
    "    for t in info_df.loc[~info_df['Type'].isnull()].loc[info_df['Symbol'] == s]['Type']:\n",
    "        temp_date = info_df.loc[info_df['Symbol'] == s].loc[info_df['Type'] == t]['Date'].values[0]\n",
    "        temp_data_before = data[s].to_frame().loc[temp_date - np.timedelta64(365,'D'):temp_date]['Adj Close']\n",
    "        temp_data_after = data[s].to_frame().loc[temp_date:temp_date + np.timedelta64(365,'D')]['Adj Close']\n",
    "        temp_dax_before = dax.loc[temp_date - np.timedelta64(365,'D'):temp_date]\n",
    "        temp_dax_after = dax.loc[temp_date:temp_date + np.timedelta64(365,'D')]\n",
    "        corr_before = temp_data_before.corr(temp_dax_before)\n",
    "        corr_after = temp_data_after.corr(temp_dax_after)\n",
    "        if temp_date == np.datetime64('2021-09-20'):\n",
    "            big_inc = True\n",
    "        else:\n",
    "            big_inc = False\n",
    "        corr_df_list.append({'Ticker': s, 'Type': t, '30 -> 40': big_inc, 'Corr_before': corr_before, 'Corr_after': corr_after, 'Delta': corr_after - corr_before})\n",
    "\n",
    "corr_df = pd.DataFrame(corr_df_list)\n",
    "corr_df.sort_values(by=['Delta'], inplace=True)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(dict.fromkeys(list(info_df.loc[~info_df['Type'].isnull()]['Symbol']))))\n",
    "#s\n",
    "#list(dict.fromkeys(list(info_df.loc[~info_df['Type'].isnull()]['Symbol'])))\n",
    "len(corr_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314e902",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Systematic Risk and Liquidity <a class=\"anchor\" id=\"7-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9964607",
   "metadata": {},
   "source": [
    "It is examined whether the inclusion of a share in the DAX affects the systematic risk and the liquidity of the share in question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe6d66",
   "metadata": {},
   "source": [
    "## Systematic Risk of all newly Stocks included in the DAX <a class=\"anchor\" id=\"8-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d611a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Calculating the systmatic risk after the inclusion of the Stocks in the DAX.\n",
    "To estimate the regression equations, OLS was used in conjunction with a correction procedure (Newey/West) \n",
    "for serially correlated error terms. \n",
    "This approach leads to test statistics that are robust against autocorrelated and \n",
    "heteroskedastic disturbance terms.\n",
    "\n",
    "Time Horizon\n",
    "----------\n",
    "Start: 2009-06-21\n",
    "End: 2022-03-01\n",
    "----------\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":sys_risk:  df\n",
    "    Stock: Name of the specific stock.\n",
    "    Rank: Sorted after index weight (ascending).\n",
    "    Delta: Measures the change in the systematic risk of the share triggered by the inclusion.\n",
    "    p-Value: The two-tailed p-values for the t-stats of the params.\n",
    "    R^2: R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "i = 0\n",
    "j = 1\n",
    "sys_risk = []\n",
    "while i in range(0,10):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_included.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_included[DAX_included.iloc[i][1]][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_included.iloc[i][0] + datetime.timedelta(days=365))])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_included.iloc[i][0] + datetime.timedelta(days=365))]\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_included.iloc[i][0] + datetime.timedelta(days=365))]\n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_included.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "  \n",
    "while i in range(10,len(returns_daily_included)):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_included.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_included[DAX_included.iloc[i][1]][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01'])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_included.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "sys_risk = pd.DataFrame(sys_risk)\n",
    "sys_risk.append(\n",
    "        {\n",
    "            'Stock': r\"$\\varnothing$\",\n",
    "            r\"$\\Delta$\": sys_risk[r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[r\"$R^{2}$\"].mean()\n",
    "        }, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e462b9",
   "metadata": {},
   "source": [
    "## Systematic Risk of all newly Stocks excluded in the DAX <a class=\"anchor\" id=\"9-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d5ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Calculating the systmatic risk after the exclusion of the Stocks in the DAX.\n",
    "To estimate the regression equations, OLS was used in conjunction with a correction procedure (Newey/West) \n",
    "for serially correlated error terms. \n",
    "This approach leads to test statistics that are robust against autocorrelated and \n",
    "heteroskedastic disturbance terms.\n",
    "\n",
    "Time Horizon\n",
    "----------\n",
    "Start: 2009-06-21\n",
    "End: 2022-03-01\n",
    "----------\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":sys_risk:  df\n",
    "    Stock: Name of the specific stock.\n",
    "    Rank: Sorted after index weight (ascending).\n",
    "    Delta: Measures the change in the systematic risk of the share triggered by the inclusion.\n",
    "    p-Value: The two-tailed p-values for the t-stats of the params.\n",
    "    R^2: R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "\n",
    "i = 0\n",
    "j = 1\n",
    "sys_risk = []\n",
    "while i in range(0,7):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_excluded.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_excluded[DAX_excluded.iloc[i][1]][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_excluded.iloc[i][0] + datetime.timedelta(days=365))])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_excluded.iloc[i][0] + datetime.timedelta(days=365))]\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_excluded.iloc[i][0] + datetime.timedelta(days=365))]   \n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_excluded.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "    \n",
    "while i in range(7,len(returns_daily_excluded)):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_excluded.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_excluded[DAX_excluded.iloc[i][1]][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01'])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_excluded.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "sys_risk = pd.DataFrame(sys_risk)\n",
    "sys_risk.append(\n",
    "        {\n",
    "            'Stock': r\"$\\varnothing$\",\n",
    "            r\"$\\Delta$\": sys_risk[r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[r\"$R^{2}$\"].mean()            \n",
    "        }, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab202a3",
   "metadata": {},
   "source": [
    "## Systematic Risk of the 10 Stocks from DAX Increase in 2021 <a class=\"anchor\" id=\"10-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating a list and dictionary with all 10 newly added DAX stocks.\n",
    "Parameters\n",
    "----------\n",
    ":newcomers:  list\n",
    "    Contains the names of the stocks.\n",
    ":dax_new: dict\n",
    "    Contains the daily returns of the 10 new stocks.\n",
    "-------\n",
    "'''\n",
    "newcomers = ['AIR.DE', 'SHL.DE', 'ZAL.DE', 'SY1.DE', 'SRT3.DE',  'POAHY', 'HFG.DE', 'BNR.DE', 'QIA.DE', 'PUM.DE']\n",
    "dax_new = {new: returns_daily[new] for new in newcomers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59843f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating the dummy variable - 0 before the inclusion day (2021-09-20) and 1 thereafter.\n",
    "Parameters\n",
    "----------\n",
    ":benchmark:  df\n",
    "    Contains daily returns as well as the dummy variable.\n",
    "-------\n",
    "'''\n",
    "d = []\n",
    "for date in benchmark.index:\n",
    "    if str(date) < '2021-09-20 00:00:00':\n",
    "        d.append(0)\n",
    "    else: d.append(1)\n",
    "benchmark['Dummy'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791debb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Calculating the systmatic risk.\n",
    "To estimate the regression equations, OLS was used in conjunction with a correction procedure (Newey/West) \n",
    "for serially correlated error terms. \n",
    "This approach leads to test statistics that are robust against autocorrelated and \n",
    "heteroskedastic disturbance terms.\n",
    "\n",
    "Time Horizon\n",
    "----------\n",
    "Start: 1 Year before the inclusion day (2020-09-20)\n",
    "End: 2022-03-01\n",
    "----------\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":sys_risk:  df\n",
    "    Stock: Name of the specific stock.\n",
    "    Rank: Sorted after index weight (ascending).\n",
    "    Delta: Measures the change in the systematic risk of the share triggered by the inclusion.\n",
    "    p-Value: The two-tailed p-values for the t-stats of the params.\n",
    "    R^2: R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "i = 1\n",
    "sys_risk = []\n",
    "for key in dax_new:\n",
    "    data = pd.DataFrame(dax_new[key]['2020-09-20':'2022-03-01'])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs']['2020-09-20':'2022-03-01']\n",
    "    data['Dummy'] = benchmark['Dummy']['2020-09-20':'2022-03-01']\n",
    "    stocks_as_df['Volume'][key]['2020-09-20':'2021-09-20']    \n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': key,\n",
    "            'Rank': i, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    i += 1\n",
    "sys_risk = pd.DataFrame(sys_risk)\n",
    "sys_risk.append(\n",
    "        {\n",
    "            'Stock': r\"$\\varnothing$\",\n",
    "            r\"$\\Delta$\": sys_risk[r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[r\"$R^{2}$\"].mean()\n",
    "        }, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Distribution of the shares with a higher unit share in the DAX and all those with a weighting of < 1 %. \n",
    "Parameters\n",
    "----------\n",
    ":des_stat:  df\n",
    "    N: Number of stocks sorted after the index weight.\n",
    "    Mean: Mean systematic risk. \n",
    "    R^2: Mean R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "des_stat = []\n",
    "des_stat.append(\n",
    "        {\n",
    "            'N': '1-5',\n",
    "            r\"$\\varnothing$\": sys_risk[:5][r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[:5][r\"$R^{2}$\"].mean()\n",
    "        }\n",
    "    )\n",
    "des_stat.append(\n",
    "        {\n",
    "            'N': '6-10',\n",
    "            r\"$\\varnothing$\": sys_risk[5:][r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[5:][r\"$R^{2}$\"].mean()\n",
    "        }\n",
    "    )\n",
    "pd.DataFrame(des_stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
