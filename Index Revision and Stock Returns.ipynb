{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b543aa1c",
   "metadata": {},
   "source": [
    "# Guided Studies into Financial Management\n",
    "## Index Revisions and Stock Returns\n",
    "\n",
    "### Colaborators\n",
    "Dennis Blaufuss,\n",
    "Lars Wrede,\n",
    "Nicolas Kepper,\n",
    "Sophie Merl,\n",
    "Philipp Voit\n",
    "\n",
    "### Instructor\n",
    "Dr. Stefan Scharnoski\n",
    "\n",
    "### Summary \n",
    "HIER MÃœSSEN WIR NOCH EINE ZUSAMMENFASSUNG DER ERGEBNISSE SCHREIBEN - WIE ABSTRACT\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc04ce",
   "metadata": {},
   "source": [
    "## Table of Content:\n",
    "1. [Data Proprocessing](#0-bullet)\n",
    "* [Import Data](#first-bullet)\n",
    "* [Calculate Daily Returns](#2-bullet)\n",
    "* [Data Quality Checks](#3-bullet)\n",
    "* [Descriptive Statistics](#4-bullet)\n",
    "2. [Price Pressure](#5-bullet)\n",
    "3. [Investor Attention](#6-bullet)\n",
    "4. [Systematic Risk and Liquidity](#7-bullet)\n",
    "* [Systematic Risk - Included Stocks](#8-bullet)\n",
    "* [Systematic Risk - Excluded Stocks](#9-bullet)\n",
    "* [Systematic Risk - DAX 30 to DAX 40](#10-bullet)\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ae388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import performanceanalytics.table.table as pat\n",
    "from performanceanalytics.charts import performance_summary\n",
    "import statistics\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208c20c3",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing <a class=\"anchor\" id=\"0-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164152d1",
   "metadata": {},
   "source": [
    "## Import Data <a class=\"anchor\" id=\"first-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbe7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Import all relevant data.\n",
    "Parameters\n",
    "----------\n",
    ":DAX_aufgenommen: df\n",
    "    All stocks included in the DAX from 2010 until 2021.\n",
    ":DAX_ausgeschieden: df\n",
    "    All stocks excluded from the DAX from 2010 until 2021.\n",
    ":stock_data: df\n",
    "    Contains stock ticker as well as names of the stocks of all DAX stock from 22-03-01.\n",
    ":benchmark:  df\n",
    "    The MSCI Germany Index was used as a proxy for the market portfolio. \n",
    "    This index contains a large number of M-DAX and DAX stocks and is therefore more \n",
    "    broadly structured than the DAX. However, the high weight of the DAX shares in the index is problematic, \n",
    "    so that it is to be expected that the actual influence is underestimated.\n",
    ":index_compositions: df\n",
    "    Contains the deletions/ additions as well as date of change/ announcements & Merger/Spin-Off Information.\n",
    "-------\n",
    "'''\n",
    "DAX_included = pd.read_csv('DAX_included_2010-2021.csv', sep = ';')\n",
    "DAX_excluded = pd.read_csv('DAX_excluded_2010-2021.csv', sep = ';')\n",
    "stock_data = pd.read_csv('Companies_Ticker.csv', sep = ';')\n",
    "benchmark = pd.read_csv('DAX_Kurs.csv', sep = ';')\n",
    "#index_compositions = pd.read_csv('Historical_Index_Compositions.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da14e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Pulls time series data for stocks on a daily basis from 2010-01-01 until 2022-03-01.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_dict:  dict\n",
    "    Contains the stock symbols as key and the time series as values.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stock_dict = {}\n",
    "for s in stock_data['Symbol']: # iterate for every stock indices\n",
    "    # Retrieve data from Yahoo Finance\n",
    "    tickerData = yf.Ticker(s)\n",
    "    # Save historical data \n",
    "    stock_dict[s] = yf.download(s, start='2010-01-01', end='2022-03-01', progress=False)\n",
    "# Concatenate all data\n",
    "stocks_as_df = pd.concat(stock_dict, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196340b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Pulls time series data for stocks on a daily basis from 2009-06-21 until 2022-03-01.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_included:  dict\n",
    "    Contains the stock symbols as key and the time series as values.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stock_included = {}\n",
    "for s in DAX_included['Symbol']: # iterate for every stock indices\n",
    "    # Retrieve data from Yahoo Finance\n",
    "    tickerData = yf.Ticker(s)\n",
    "    # Save historical data \n",
    "    stock_included[s] = yf.download(s, start='2009-06-21', end='2022-03-01', progress=False)\n",
    "stock_included_as_df = pd.concat(stock_included, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Pulls time series data for stocks on a daily basis from 2009-06-21 until 2022-03-01.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_included:  dict\n",
    "    Contains the stock symbols as key and the time series as values.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stock_excluded = {}\n",
    "for s in DAX_excluded['Symbol']: # iterate for every stock indices\n",
    "    # Retrieve data from Yahoo Finance\n",
    "    tickerData = yf.Ticker(s)\n",
    "    # Save historical data \n",
    "    stock_excluded[s] = yf.download(s, start='2009-06-21', end='2022-03-01', progress=False)\n",
    "stock_excluded_as_df = pd.concat(stock_excluded, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238db965",
   "metadata": {},
   "source": [
    "## Calculate Daily Returns <a class=\"anchor\" id=\"2-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Transform daily price data to daily returns.\n",
    "Parameters\n",
    "----------\n",
    ":returns_daily:  dict\n",
    "    Contains the stock symbols as key and the daily returns as values.\n",
    ":returns_daily_excluded: dict\n",
    "    Contains the stock symbols as key and the daily returns as values.\n",
    ":returns_daily_included: dict\n",
    "    Contains the stock symbols as key and the daily returns as values.\n",
    ":benchmark: df\n",
    "    Contains daily returns from the benchmark.\n",
    "-------\n",
    "'''\n",
    "returns_daily = {}\n",
    "for s in stock_data['Symbol']:\n",
    "    returns_daily[s] = stock_dict[s]['Adj Close'].pct_change()\n",
    "returns_daily_included = {}\n",
    "for s in DAX_included['Symbol']:\n",
    "    returns_daily_included[s] = stock_included[s]['Adj Close'].pct_change()\n",
    "DAX_included['Aufgenommen'] = pd.to_datetime(DAX_included['Aufgenommen'], format='%d.%m.%Y')\n",
    "\n",
    "returns_daily_excluded = {}\n",
    "for s in DAX_excluded['Symbol']:\n",
    "    returns_daily_excluded[s] = stock_excluded[s]['Adj Close'].pct_change()\n",
    "DAX_excluded['Ausgeschieden'] = pd.to_datetime(DAX_excluded['Ausgeschieden'], format='%d.%m.%Y')\n",
    "    \n",
    "benchmark['Umtauschdatum'] = pd.to_datetime(benchmark['Umtauschdatum'], format='%d.%m.%y')\n",
    "benchmark = pd.DataFrame(benchmark['Schlusskurs'].astype(float).pct_change()).set_index(benchmark['Umtauschdatum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2719f35",
   "metadata": {},
   "source": [
    "## Data Quality Checks <a class=\"anchor\" id=\"3-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80afc6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check if stocks_as_df contains NA or zeros in Volume & Adjusted Close.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stocks_as_df:  df\n",
    "    Contains the time series data as one df.\n",
    ":stocks_as_df_Volume_is_0:  df\n",
    "    Contains the rows where Volume == 0.\n",
    "-------\n",
    "'''\n",
    "\n",
    "stocks_as_df_has_nan = np.isnan(np.sum(stocks_as_df)) #no NAs\n",
    "\n",
    "#(stocks_as_df < 0).any()\n",
    "#(stocks_as_df = 0).any()\n",
    "\n",
    "stocks_as_df_Volume_is_0 = stocks_as_df.loc[stocks_as_df[\"Volume\"] == 0] #2774 times 0\n",
    "stocks_as_df_AdjClose_is_0 = stocks_as_df.loc[stocks_as_df[\"Adj Close\"] == 0] #never 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5749a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Interpolate Volume using 'spline'.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stock_dict_replaced:  dict\n",
    "    Contains the time series data as stock_dict but with interpolated values for 'Volume'.\n",
    "-------\n",
    "'''\n",
    "stock_dict_replaced = stock_dict\n",
    "for key in stock_dict_replaced:\n",
    "    stock_dict_replaced[key].loc[stock_dict_replaced[key]['Volume'] == 0, 'Volume'] = np.nan\n",
    "    stock_dict_replaced[key]['Volume'].interpolate(method ='spline', order = 2, inplace=True)\n",
    "\n",
    "#stock_dict_replaced['ZAL.DE'] #stock_dict 2014-10-06 should now have an interpolated value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42147c21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de66a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Check if Adj Close in stocks_as_df differs from previous/ following day.\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":stocks_as_df:  df\n",
    "    Contains the time series data as one df.\n",
    ":stocks_as_df_adjclose_peak_bottom:  dataframe\n",
    "    Contains the rows where Adj. Close differs\n",
    "-------\n",
    "'''\n",
    "stocks_as_df_adjclose_peak_bottom_list = []\n",
    "n = 1\n",
    "\n",
    "while n < len(stocks_as_df)-1:\n",
    "    if abs(stocks_as_df['Adj Close'][n] -\n",
    "           statistics.mean([stocks_as_df['Adj Close'][n-1],\n",
    "                            stocks_as_df['Adj Close'][n+1]])) > .5 * stocks_as_df['Adj Close'][n]:\n",
    "        stocks_as_df_adjclose_peak_bottom_list.append(stocks_as_df.iloc[n])\n",
    "\n",
    "    n += 1\n",
    "\n",
    "stocks_as_df_adjclose_peak_bottom = pd.DataFrame(stocks_as_df_adjclose_peak_bottom_list) #29 times "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a9b548",
   "metadata": {},
   "source": [
    "## Descriptive Statistics of the whole Dataset <a class=\"anchor\" id=\"4-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Calculating measures of location, statistical dispersion and shape.\n",
    "Parameters\n",
    "----------\n",
    ":des_stat:  dataframe\n",
    "    Contains the descriptive statistics.\n",
    "-------\n",
    "'''\n",
    "\n",
    "des_stat = pd.DataFrame(columns=stock_data['Symbol'], \n",
    "                        index=['Observations', 'NAs', 'Minimum', 'Quartile 1', 'Median', \n",
    "                               'Artithmetic Mean', 'Geometric Mean', 'Quartile 3', 'Maximum', 'SE Mean',\n",
    "                               'LCL Mean (.95)', 'UCL Mean (.95)', 'Variance', 'Stdev', 'Skewness','Kurtosis'])\n",
    "\n",
    "for s in stock_data['Symbol']:\n",
    "    df = pd.DataFrame(returns_daily[s])\n",
    "    des_stat[s] = pat.stats_table(df, manager_col=0)\n",
    "des_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74165ff8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' Calculating the downside statistics.\n",
    "Parameters\n",
    "----------\n",
    ":down_stat:  dataframe\n",
    "    Contains the downside statistics.\n",
    "-------\n",
    "'''\n",
    "#down_stat = pd.DataFrame(columns=stock_data['Symbol'], \n",
    "#                        index=['Semi Deviation', 'Gain Deviation', 'Loss Deviation', 'Downside Deviation (MAR=2.0%)',\n",
    "#                               'Downside Deviation (rf=0.5%)', 'Downside Deviation (0%)', 'Maximum Drawdown', \n",
    "#                               'Historical VaR (95%)', 'Historical ES (95%)', 'Modified VaR (95%)', 'Modified ES (95%)'])\n",
    "\n",
    "#for s in stock_data['Symbol']:\n",
    "#    df = pd.DataFrame(returns_daily[s])\n",
    "#    down_stat[s] = pat.create_downside_table(df,0)\n",
    "#down_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e4cd9",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Price Pressure <a class=\"anchor\" id=\"5-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all dicts into a single one\n",
    "stock_dict = {**stock_dict, **stock_included, **stock_excluded}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8864b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def calc_mvr_multiple_days(year_start, year_end, inclusions, day_range, stocks, market_symbol):\n",
    "    \"\"\"\n",
    "    Calculates MVR measures and takes the average over multiple days.\n",
    "        \n",
    "    :param year_start:\n",
    "        year in which to start checking for inclusions to the index\n",
    "    :param year_end:\n",
    "        year in which to end checking for inclusions to the index\n",
    "    :param inclusions:\n",
    "        dataframe showing inclusions to an index\n",
    "        Needed columns:\n",
    "            Aufgenommen - Date included to the index\n",
    "            Symbol - stock's symbol\n",
    "    :param day_range:\n",
    "        range of days for \"event period\" i\n",
    "    :param stock:\n",
    "        stock data for the entire time horizon\n",
    "    :param market_symbol:\n",
    "        stock symbol for the market for the entire time horizon\n",
    "        \n",
    "    :return:\n",
    "        mean, stddev, N of all Volume Ratios of included stocks in the selected time period\n",
    "    \"\"\"\n",
    "    s = pd.Series([], dtype='float64')\n",
    "    for i in day_range:\n",
    "        s_, _, _, n = calc_mvr(year_start, year_end, inclusions, i, stocks, market_symbol)\n",
    "        s.append(s_)\n",
    "    return s, s.mean(), s.std(), n\n",
    "    \n",
    "\n",
    "def calc_mvr(year_start, year_end, inclusions, day, stocks, market_symbol):\n",
    "    \"\"\"\n",
    "    MVR of stock i is the mean VR (Volume Ratio) for event period t\n",
    "    VR of stock i is the ratio of Volume of stock i traded in period t to volume traded in the market times volume traded \n",
    "        in the market over the past 8 weeks over volume of stock i in the past 8 weeks\n",
    "        \n",
    "    :param year_start:\n",
    "        year in which to start checking for inclusions to the index\n",
    "    :param year_end:\n",
    "        year in which to end checking for inclusions to the index\n",
    "    :param inclusions:\n",
    "        dataframe showing inclusions to an index\n",
    "        Needed columns:\n",
    "            Aufgenommen - Date included to the index\n",
    "            Symbol - stock's symbol\n",
    "    :param day:\n",
    "        how many days after the announcement date is the \"event period\" i?\n",
    "    :param stock:\n",
    "        stock data for the entire time horizon\n",
    "    :param market_symbol:\n",
    "        stock symbol for the market for the entire time horizon\n",
    "        \n",
    "    :return:\n",
    "        series (the series of VRs), mean, stddev, N of all Volume Ratios of included stocks in the selected time period\n",
    "    \"\"\"\n",
    "    \n",
    "    year_start = datetime.strptime('01.01.' + str(year_start), '%d.%m.%Y')\n",
    "    year_end = datetime.strptime('31.12.' + str(year_end), '%d.%m.%Y')\n",
    "    \n",
    "    inclusions_in_time_period = inclusions[(inclusions['Aufgenommen'] >= year_start) & (inclusions['Aufgenommen'] <= year_end)]\n",
    "    \n",
    "    apply_calc_vr = lambda row: calc_vr(row['Aufgenommen'], day, stocks[row['Symbol']], stocks[market_symbol])\n",
    "    vr_series = inclusions_in_time_period.apply(apply_calc_vr, axis=1)\n",
    "    return vr_series, vr_series.mean(), vr_series.std(), vr_series.size\n",
    "    \n",
    "    \n",
    "def calc_vr(announcement_date, day, stock, market):\n",
    "    \"\"\"\n",
    "    VR of stock i is the ratio of Volume of stock i traded in period t to volume traded in the market times volume traded \n",
    "        in the market over the past 8 weeks over volume of stock i in the past 8 weeks\n",
    "    $ VR_{it} = \\frac{V_{it}}{V_{mt}} * \\frac{V_m}{V_i} $\n",
    "    \n",
    "    :param announcement_date:\n",
    "        the announcement date\n",
    "    :param day:\n",
    "        how many days after the announcement date is the \"event period\" i?\n",
    "    :param stock:\n",
    "        stock data for the entire time horizon\n",
    "    :param market:\n",
    "        stock data for the market for the entire time horizon\n",
    "    \"\"\"\n",
    "    \n",
    "    start_date = announcement_date - timedelta(weeks=8)\n",
    "    i = announcement_date + timedelta(days=day)\n",
    "    \n",
    "    i_slice = stock[(stock.index >= start_date) & (stock.index <= i)]\n",
    "    m_slice = market[(market.index >= start_date) & (market.index <= i)]\n",
    "    \n",
    "    v_it = stock[stock.index == i]['Volume'].values[0]\n",
    "    v_mt = market[market.index == i]['Volume'].values[0]\n",
    "    \n",
    "    v_i = np.mean(i_slice['Volume'])\n",
    "    v_m = np.mean(m_slice['Volume'])\n",
    "    \n",
    "    return (v_it / v_mt) * (v_m / v_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf2069",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_mvr_multiple_days(2010, 2013, DAX_included,  range(1, 6), stock_dict, '^GDAXI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "year_ranges = [(2010, 2021), (2010, 2015), (2016, 2021)]\n",
    "year_ranges += [(x, x) for x in range(2010, 2022)]\n",
    "\n",
    "df = pd.DataFrame(columns=['N', 'MVR Day 1', 'STD Day 1', 't Day 1', '% > 1 Day 1', 'MVR Day 1-5', 'STD Day 1-5', 't Day 1-5', '% > 1 Day 1-5'])\n",
    "\n",
    "for (y1, y2) in year_ranges:\n",
    "    s, m, stdev, n = calc_mvr(y1, y2, DAX_included, 1, stock_dict, '^GDAXI')\n",
    "    t = scipy.stats.testt_1samp(series, 1)\n",
    "    p = s.gt(1).sum() / s.size\n",
    "    d = {'N': n, 'MVR Day 1': m, 'STD Day 1': stdev, 't Day 1': t, '% > 1 Day 1': p}\n",
    "    s, m, stdev, _ = calc_mvr_multiple_days(y1, y2, DAX_included, range(1, 6), stock_dict, '^GDAXI')\n",
    "    d['MVR Day 1-5'] = m\n",
    "    d['STD Day 1-5'] = stdev\n",
    "    d['t Day 1-5'] = scipy.stats.testt_1samp(s, 1)\n",
    "    d['% > 1 Day 1-5'] = s.gt(1).sum() / s.size\n",
    "    df = df.append(pd.DataFrame(data=d, index=[str(y1) if y1 == y2 else str(y1) + '-' + str(y2)]))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85beec6f",
   "metadata": {},
   "source": [
    "__To-Do's__\n",
    "* Welche Index Inklusion Effekte gibt es.\n",
    "* Gibt es einen Pre-announcement drift? \n",
    "* Gibt es sonstige Announcement Effekte?\n",
    "\n",
    "__Paper 1 EMH vs. PPH nachbauen__\n",
    "* Alle Aktien fÃ¼r die Analyse zusammen suchen - bisher sind nur die neusten 40 enthalten (Sophie hat hier schon eine CSV vorbereitet).\n",
    "*    Analyse excess return & trading volume on the first 5 days with the cross sectional means.\n",
    "*    Analysis before and after annoucment as well as after the inclusion day\n",
    "\n",
    "* VorschlÃ¤ge hierzu von Stefan:\n",
    "    * Alles Herausnahmen und Hereinnahmen in den DAX zusammennehmen, da nur so statistische Test mÃ¶glich sind\n",
    "    * Bspw. vor 2010, nach 2010 VerÃ¤nderungen anschauen\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb718155",
   "metadata": {},
   "source": [
    "Ã„nderungsvorschlÃ¤ge von Stefan\n",
    "\tâ€¢\tAlles Ã„nderungen zusammen (30 auf 40)\n",
    "--> inferenzen, statistischen tests nur so mÃ¶glich\n",
    "\tâ€¢\tVor 2010, nach 2010\n",
    "\tâ€¢\tÃœberlegen, wie wir das empirisch machen --> counterfactual\n",
    "\tâ€¢\tAbnormal returns, worauf basiert es; was ist expected return; komplexeres modell\n",
    "\tâ€¢\tIndex Inklusion Effekte\n",
    "\tâ€¢\tFreiheitsgrade im empirischen Ansatz, solange die Frage beantwortet wird wie sich Inklusion auf Expected Returns und andere Metriken auswirkt\n",
    "\tâ€¢\tAbnormal returns; VolatilitÃ¤t; Handelsvolumen (ETFs mÃ¼ssen sie nun auch handeln); Investors attention (das sollten wir absprechen; ggf. Aufnahme in Index als MaÃŸ fÃ¼r Attention; dazu: googeln)\n",
    "\tâ€¢\tKorrelationen: Wie Ã¤ndern sich Korrelation (das kÃ¶nnte attention sein) --> Ã¶konomisch bedeutsam, weil systematisches Risiko\n",
    "\tâ€¢\tGgf. Datenfiltern; Daten Fehler; fÃ¼r Preise funktioniert gut; Handelsvolumen nicht so zuverlÃ¤ssig fÃ¼r damals\n",
    "\tâ€¢\tWichtig, dass Tage stimmen, ansonsten problematisch\n",
    "\tâ€¢\tAnnouncement day & inclusion day\n",
    "\tâ€¢\tPre-announcement drift\n",
    "\tâ€¢\tAnnouncement Effekte\n",
    "\tâ€¢\tDividends announcements --> Literatur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b9cc78",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Correlation Analysis <a class=\"anchor\" id=\"6-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3155f94",
   "metadata": {},
   "source": [
    "__To-Do's__ \n",
    "* Welche Index Inklusion Effekte gibt es.\n",
    "* Gibt es einen Pre-announcement drift? \n",
    "* Gibt es sonstige Announcement Effekte?\n",
    "\n",
    "__Paper 2 Investor Attention am Ende nachbauen__\n",
    "* Korrelationen: Wie Ã¤ndern sich Korrelation (das kÃ¶nnte attention sein) --> Ã¶konomisch bedeutsam, weil systematisches Risiko --> HinfÃ¼hrung zum 4. Teil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Calculating the change in correlation between each stock and the index itself before and after introduction to it.\n",
    "The Dates will be standardized (as of t = 0 is the inclusion day) to better visualize.\n",
    "The correlation will be calculated based on the last 10 days\n",
    "\n",
    "\n",
    "Time Horizon\n",
    "----------\n",
    "Start: 2009-06-21\n",
    "End: 2022-03-01\n",
    "----------\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "data = returns_daily_included\n",
    "dax = returns_daily['^GDAXI']\n",
    "\n",
    "for s in DAX_included['Symbol']:\n",
    "    temp_date = DAX_included.loc[DAX_included['Symbol'] == s]['Aufgenommen'].values[0]\n",
    "    temp_data_before = data[s].to_frame().loc[:temp_date]['Adj Close']\n",
    "    temp_data_after = data[s].to_frame().loc[temp_date:]['Adj Close']\n",
    "    temp_dax_before = dax.loc[:temp_date]\n",
    "    temp_dax_after = dax.loc[temp_date:]\n",
    "    corr_before = temp_data_before.corr(temp_dax_before)\n",
    "    corr_after = temp_data_after.corr(temp_dax_after)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4314e902",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Systematic Risk and Liquidity <a class=\"anchor\" id=\"7-bullet\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9964607",
   "metadata": {},
   "source": [
    "It is examined whether the inclusion of a share in the DAX affects the systematic risk and the liquidity of the share in question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe6d66",
   "metadata": {},
   "source": [
    "## Systematic Risk of all newly Stocks included in the DAX <a class=\"anchor\" id=\"8-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d611a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Calculating the systmatic risk after the inclusion of the Stocks in the DAX.\n",
    "To estimate the regression equations, OLS was used in conjunction with a correction procedure (Newey/West) \n",
    "for serially correlated error terms. \n",
    "This approach leads to test statistics that are robust against autocorrelated and \n",
    "heteroskedastic disturbance terms.\n",
    "\n",
    "Time Horizon\n",
    "----------\n",
    "Start: 2009-06-21\n",
    "End: 2022-03-01\n",
    "----------\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":sys_risk:  df\n",
    "    Stock: Name of the specific stock.\n",
    "    Rank: Sorted after index weight (ascending).\n",
    "    Delta: Measures the change in the systematic risk of the share triggered by the inclusion.\n",
    "    p-Value: The two-tailed p-values for the t-stats of the params.\n",
    "    R^2: R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "i = 0\n",
    "j = 1\n",
    "sys_risk = []\n",
    "while i in range(0,10):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_included.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_included[DAX_included.iloc[i][1]][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_included.iloc[i][0] + datetime.timedelta(days=365))])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_included.iloc[i][0] + datetime.timedelta(days=365))]\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_included.iloc[i][0] + datetime.timedelta(days=365))]\n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_included.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "  \n",
    "while i in range(10,len(returns_daily_included)):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_included.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_included[DAX_included.iloc[i][1]][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01'])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_included.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_included.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "sys_risk = pd.DataFrame(sys_risk)\n",
    "sys_risk.append(\n",
    "        {\n",
    "            'Stock': r\"$\\varnothing$\",\n",
    "            r\"$\\Delta$\": sys_risk[r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[r\"$R^{2}$\"].mean()\n",
    "        }, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e462b9",
   "metadata": {},
   "source": [
    "## Systematic Risk of all newly Stocks excluded in the DAX <a class=\"anchor\" id=\"9-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82d5ad9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Calculating the systmatic risk after the exclusion of the Stocks in the DAX.\n",
    "To estimate the regression equations, OLS was used in conjunction with a correction procedure (Newey/West) \n",
    "for serially correlated error terms. \n",
    "This approach leads to test statistics that are robust against autocorrelated and \n",
    "heteroskedastic disturbance terms.\n",
    "\n",
    "Time Horizon\n",
    "----------\n",
    "Start: 2009-06-21\n",
    "End: 2022-03-01\n",
    "----------\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":sys_risk:  df\n",
    "    Stock: Name of the specific stock.\n",
    "    Rank: Sorted after index weight (ascending).\n",
    "    Delta: Measures the change in the systematic risk of the share triggered by the inclusion.\n",
    "    p-Value: The two-tailed p-values for the t-stats of the params.\n",
    "    R^2: R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "\n",
    "i = 0\n",
    "j = 1\n",
    "sys_risk = []\n",
    "while i in range(0,7):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_excluded.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_excluded[DAX_excluded.iloc[i][1]][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_excluded.iloc[i][0] + datetime.timedelta(days=365))])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_excluded.iloc[i][0] + datetime.timedelta(days=365))]\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):str(DAX_excluded.iloc[i][0] + datetime.timedelta(days=365))]   \n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_excluded.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "    \n",
    "while i in range(7,len(returns_daily_excluded)):\n",
    "    d = []\n",
    "    for date in benchmark.index:\n",
    "        if str(date) < str(DAX_excluded.iloc[i][0]):\n",
    "            d.append(0)\n",
    "        else: d.append(1)\n",
    "    benchmark['Dummy'] = d\n",
    "\n",
    "    data = pd.DataFrame(returns_daily_excluded[DAX_excluded.iloc[i][1]][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01'])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data['Dummy'] = benchmark['Dummy'][str(DAX_excluded.iloc[i][0] - datetime.timedelta(days=365)):'2022-03-01']\n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': DAX_excluded.iloc[i][1],\n",
    "            'Rank': j, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    j += 1\n",
    "    i += 1\n",
    "sys_risk = pd.DataFrame(sys_risk)\n",
    "sys_risk.append(\n",
    "        {\n",
    "            'Stock': r\"$\\varnothing$\",\n",
    "            r\"$\\Delta$\": sys_risk[r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[r\"$R^{2}$\"].mean()            \n",
    "        }, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab202a3",
   "metadata": {},
   "source": [
    "## Systematic Risk of the 10 Stocks from DAX Increase in 2021 <a class=\"anchor\" id=\"10-bullet\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ba9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating a list and dictionary with all 10 newly added DAX stocks.\n",
    "Parameters\n",
    "----------\n",
    ":newcomers:  list\n",
    "    Contains the names of the stocks.\n",
    ":dax_new: dict\n",
    "    Contains the daily returns of the 10 new stocks.\n",
    "-------\n",
    "'''\n",
    "newcomers = ['AIR.DE', 'SHL.DE', 'ZAL.DE', 'SY1.DE', 'SRT3.DE',  'POAHY', 'HFG.DE', 'BNR.DE', 'QIA.DE', 'PUM.DE']\n",
    "dax_new = {new: returns_daily[new] for new in newcomers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59843f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating the dummy variable - 0 before the inclusion day (2021-09-20) and 1 thereafter.\n",
    "Parameters\n",
    "----------\n",
    ":benchmark:  df\n",
    "    Contains daily returns as well as the dummy variable.\n",
    "-------\n",
    "'''\n",
    "d = []\n",
    "for date in benchmark.index:\n",
    "    if str(date) < '2021-09-20 00:00:00':\n",
    "        d.append(0)\n",
    "    else: d.append(1)\n",
    "benchmark['Dummy'] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791debb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "''' Calculating the systmatic risk.\n",
    "To estimate the regression equations, OLS was used in conjunction with a correction procedure (Newey/West) \n",
    "for serially correlated error terms. \n",
    "This approach leads to test statistics that are robust against autocorrelated and \n",
    "heteroskedastic disturbance terms.\n",
    "\n",
    "Time Horizon\n",
    "----------\n",
    "Start: 1 Year before the inclusion day (2020-09-20)\n",
    "End: 2022-03-01\n",
    "----------\n",
    "\n",
    "Parameters\n",
    "----------\n",
    ":sys_risk:  df\n",
    "    Stock: Name of the specific stock.\n",
    "    Rank: Sorted after index weight (ascending).\n",
    "    Delta: Measures the change in the systematic risk of the share triggered by the inclusion.\n",
    "    p-Value: The two-tailed p-values for the t-stats of the params.\n",
    "    R^2: R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "i = 1\n",
    "sys_risk = []\n",
    "for key in dax_new:\n",
    "    data = pd.DataFrame(dax_new[key]['2020-09-20':'2022-03-01'])\n",
    "    data['Benchmark'] = benchmark['Schlusskurs']['2020-09-20':'2022-03-01']\n",
    "    data['Dummy'] = benchmark['Dummy']['2020-09-20':'2022-03-01']\n",
    "    stocks_as_df['Volume'][key]['2020-09-20':'2021-09-20']    \n",
    "    data = data.rename(columns = {'Adj Close': 'y', 'Dummy': 'D', 'Benchmark': 'x'})\n",
    "    reg = smf.ols('y ~ x + D*x', data).fit(cov_type='HAC',cov_kwds={'maxlags':1})\n",
    "    sys_risk.append(\n",
    "        {\n",
    "            'Stock': key,\n",
    "            'Rank': i, \n",
    "            r\"$\\Delta$\": reg.params[3], \n",
    "            'p_Value': reg.pvalues[3], \n",
    "            r\"$R^{2}$\": reg.rsquared\n",
    "        }\n",
    "    )\n",
    "    i += 1\n",
    "sys_risk = pd.DataFrame(sys_risk)\n",
    "sys_risk.append(\n",
    "        {\n",
    "            'Stock': r\"$\\varnothing$\",\n",
    "            r\"$\\Delta$\": sys_risk[r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[r\"$R^{2}$\"].mean()\n",
    "        }, ignore_index=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Distribution of the shares with a higher unit share in the DAX and all those with a weighting of < 1 %. \n",
    "Parameters\n",
    "----------\n",
    ":des_stat:  df\n",
    "    N: Number of stocks sorted after the index weight.\n",
    "    Mean: Mean systematic risk. \n",
    "    R^2: Mean R-squared of the model.\n",
    "-------\n",
    "'''\n",
    "des_stat = []\n",
    "des_stat.append(\n",
    "        {\n",
    "            'N': '1-5',\n",
    "            r\"$\\varnothing$\": sys_risk[:5][r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[:5][r\"$R^{2}$\"].mean()\n",
    "        }\n",
    "    )\n",
    "des_stat.append(\n",
    "        {\n",
    "            'N': '6-10',\n",
    "            r\"$\\varnothing$\": sys_risk[5:][r\"$\\Delta$\"].mean(),\n",
    "            r\"$R^{2}$\": sys_risk[5:][r\"$R^{2}$\"].mean()\n",
    "        }\n",
    "    )\n",
    "pd.DataFrame(des_stat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
